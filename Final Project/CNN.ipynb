{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-14T06:40:01.591191Z","iopub.execute_input":"2022-12-14T06:40:01.592076Z","iopub.status.idle":"2022-12-14T06:40:05.975565Z","shell.execute_reply.started":"2022-12-14T06:40:01.591971Z","shell.execute_reply":"2022-12-14T06:40:05.974519Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/faces-age-detection-dataset/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:05.977623Z","iopub.execute_input":"2022-12-14T06:40:05.978341Z","iopub.status.idle":"2022-12-14T06:40:06.009710Z","shell.execute_reply.started":"2022-12-14T06:40:05.978301Z","shell.execute_reply":"2022-12-14T06:40:06.008712Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:06.011324Z","iopub.execute_input":"2022-12-14T06:40:06.011980Z","iopub.status.idle":"2022-12-14T06:40:06.031726Z","shell.execute_reply.started":"2022-12-14T06:40:06.011941Z","shell.execute_reply":"2022-12-14T06:40:06.030736Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"          ID   Class\n0    377.jpg  MIDDLE\n1  17814.jpg   YOUNG\n2  21283.jpg  MIDDLE\n3  16496.jpg   YOUNG\n4   4487.jpg  MIDDLE\n5   6283.jpg  MIDDLE\n6  23495.jpg   YOUNG\n7   7100.jpg   YOUNG\n8   6028.jpg   YOUNG\n9  22617.jpg     OLD","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>377.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17814.jpg</td>\n      <td>YOUNG</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21283.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16496.jpg</td>\n      <td>YOUNG</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4487.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6283.jpg</td>\n      <td>MIDDLE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>23495.jpg</td>\n      <td>YOUNG</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7100.jpg</td>\n      <td>YOUNG</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>6028.jpg</td>\n      <td>YOUNG</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>22617.jpg</td>\n      <td>OLD</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset['Class'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:06.034488Z","iopub.execute_input":"2022-12-14T06:40:06.035073Z","iopub.status.idle":"2022-12-14T06:40:06.048296Z","shell.execute_reply.started":"2022-12-14T06:40:06.035036Z","shell.execute_reply":"2022-12-14T06:40:06.047189Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['MIDDLE', 'YOUNG', 'OLD'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"dataset['Class'].hist()","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:06.049948Z","iopub.execute_input":"2022-12-14T06:40:06.050594Z","iopub.status.idle":"2022-12-14T06:40:06.312053Z","shell.execute_reply.started":"2022-12-14T06:40:06.050559Z","shell.execute_reply":"2022-12-14T06:40:06.311095Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"dataset['Class'].replace(['YOUNG', 'MIDDLE','OLD'], [0, 1, 2], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:06.313709Z","iopub.execute_input":"2022-12-14T06:40:06.314057Z","iopub.status.idle":"2022-12-14T06:40:06.327690Z","shell.execute_reply.started":"2022-12-14T06:40:06.314029Z","shell.execute_reply":"2022-12-14T06:40:06.326756Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.callbacks import TensorBoard\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:06.329255Z","iopub.execute_input":"2022-12-14T06:40:06.329921Z","iopub.status.idle":"2022-12-14T06:40:13.050698Z","shell.execute_reply.started":"2022-12-14T06:40:06.329883Z","shell.execute_reply":"2022-12-14T06:40:13.049667Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Methods for loading images.\ndef imageReader(path,ch = 3, resize=(64,64)):\n    kp = tf.io.read_file(path)\n    kp = tf.image.decode_jpeg(kp, channels=ch)\n    kp = tf.image.convert_image_dtype(kp, dtype=tf.float32)\n    kp = tf.image.resize(kp, resize)\n    return kp\n\ndef load_data(image_path, label):\n    image = imageReader(image_path, 3, (64,64))\n    \n    return (image, label)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:13.052291Z","iopub.execute_input":"2022-12-14T06:40:13.052983Z","iopub.status.idle":"2022-12-14T06:40:13.060147Z","shell.execute_reply.started":"2022-12-14T06:40:13.052944Z","shell.execute_reply":"2022-12-14T06:40:13.058969Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import glob\n# Initializing image paths variables.\nimage_paths = glob.glob('/kaggle/input/faces-age-detection-dataset/Train/*.jpg')\nprint(len(image_paths))","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:13.061739Z","iopub.execute_input":"2022-12-14T06:40:13.062384Z","iopub.status.idle":"2022-12-14T06:40:13.127385Z","shell.execute_reply.started":"2022-12-14T06:40:13.062346Z","shell.execute_reply":"2022-12-14T06:40:13.125772Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"19906\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize label values\nlabel_list = []\nfor i in image_paths:\n    _,tail = os.path.split(i)\n    label = dataset.loc[dataset['ID'] == tail]['Class'].values[0]\n    label_list.append(label)\n# print(len(label_list))","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:13.131075Z","iopub.execute_input":"2022-12-14T06:40:13.131372Z","iopub.status.idle":"2022-12-14T06:40:48.515697Z","shell.execute_reply.started":"2022-12-14T06:40:13.131346Z","shell.execute_reply":"2022-12-14T06:40:48.514667Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Create Train, Test, and Validation datasets\ntrain_size = int(0.8*(len(image_paths)))\ntest_size = 20\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((image_paths[:train_size], label_list[:train_size]))\ntest_dataset = tf.data.Dataset.from_tensor_slices((image_paths[train_size:train_size + test_size], label_list[train_size :train_size + test_size]))\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((image_paths[train_size + test_size:], label_list[train_size + test_size:]))","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:48.517412Z","iopub.execute_input":"2022-12-14T06:40:48.518003Z","iopub.status.idle":"2022-12-14T06:40:52.516504Z","shell.execute_reply.started":"2022-12-14T06:40:48.517963Z","shell.execute_reply":"2022-12-14T06:40:52.515413Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2022-12-14 06:40:48.707329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:48.708627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:48.821001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:48.821897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:48.822708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:48.823523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:48.826511: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-14 06:40:49.079256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:49.080188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:49.080974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:49.081670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:49.082350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:49.083072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:52.073534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:52.074444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:52.075176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:52.075935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:52.076714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:52.077453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-12-14 06:40:52.081155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-14 06:40:52.081924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating Autotune objects\n# For Autotune objects the prefetch buffer sizes are automitically tuned. \nAUTOTUNE = tf.data.AUTOTUNE\ntrain_dataset = (train_dataset\n    .map(load_data, num_parallel_calls=AUTOTUNE)\n    .batch(64)\n    .prefetch(AUTOTUNE)\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:52.518253Z","iopub.execute_input":"2022-12-14T06:40:52.518956Z","iopub.status.idle":"2022-12-14T06:40:52.648204Z","shell.execute_reply.started":"2022-12-14T06:40:52.518917Z","shell.execute_reply":"2022-12-14T06:40:52.647233Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Adding data agumentation to training images.\n# Data agumentation adds variation to training data\ntrain_dataset = train_dataset.map(\n    lambda image, label: (tf.image.random_flip_left_right(image), label)\n).cache(\n).map(\n    lambda image, label: (tf.image.per_image_standardization(image), label)\n).map(\n    lambda image, label: (tf.image.random_contrast(image, lower=0.4, upper=0.6), label)\n).map(\n    lambda image, label: (tf.image.random_brightness(image, max_delta = 0.4), label)\n).map(\n    lambda image, label: (tf.image.random_hue(image, max_delta = 0.4), label)\n).map(\n    lambda image, label: (tf.image.random_saturation(image, lower=0.4, upper=0.6), label)\n).shuffle(\n    1000\n).repeat(2)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:52.649794Z","iopub.execute_input":"2022-12-14T06:40:52.650144Z","iopub.status.idle":"2022-12-14T06:40:52.826524Z","shell.execute_reply.started":"2022-12-14T06:40:52.650109Z","shell.execute_reply":"2022-12-14T06:40:52.825408Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\nvalidation_dataset = (validation_dataset\n    .map(load_data, num_parallel_calls=AUTOTUNE)\n    .batch(64)\n    .prefetch(AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:52.830330Z","iopub.execute_input":"2022-12-14T06:40:52.830646Z","iopub.status.idle":"2022-12-14T06:40:52.849920Z","shell.execute_reply.started":"2022-12-14T06:40:52.830616Z","shell.execute_reply":"2022-12-14T06:40:52.848981Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Adding data agumentation to validation images.\nvalidation_dataset = validation_dataset.map(\n    lambda image, label: (tf.image.random_flip_left_right(image), label)\n).cache(\n).map(\n    lambda image, label: (tf.image.per_image_standardization(image), label)\n).map(\n    lambda image, label: (tf.image.random_contrast(image, lower=0.4, upper=0.6), label)\n).map(\n    lambda image, label: (tf.image.random_brightness(image, max_delta = 0.4), label)\n).map(\n    lambda image, label: (tf.image.random_hue(image, max_delta = 0.4), label)\n).map(\n    lambda image, label: (tf.image.random_saturation(image, lower=0.4, upper=0.6), label)\n).shuffle(\n    1000\n).repeat(2)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:52.851609Z","iopub.execute_input":"2022-12-14T06:40:52.852002Z","iopub.status.idle":"2022-12-14T06:40:53.022188Z","shell.execute_reply.started":"2022-12-14T06:40:52.851964Z","shell.execute_reply":"2022-12-14T06:40:53.021212Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_dataset = (test_dataset\n    .map(load_data, num_parallel_calls=AUTOTUNE)\n    .batch(64)\n    .prefetch(AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:53.023940Z","iopub.execute_input":"2022-12-14T06:40:53.024339Z","iopub.status.idle":"2022-12-14T06:40:53.044437Z","shell.execute_reply.started":"2022-12-14T06:40:53.024300Z","shell.execute_reply":"2022-12-14T06:40:53.043586Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Standardizing the test data.\ntest_dataset = test_dataset.map(\n    lambda image, label: (tf.image.per_image_standardization(image), label)\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:53.046997Z","iopub.execute_input":"2022-12-14T06:40:53.047929Z","iopub.status.idle":"2022-12-14T06:40:53.083113Z","shell.execute_reply.started":"2022-12-14T06:40:53.047888Z","shell.execute_reply":"2022-12-14T06:40:53.082203Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n\n\n#create model\nmodel = Sequential()\n# convolutional layer\nmodel.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(64, 64, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:53.085064Z","iopub.execute_input":"2022-12-14T06:40:53.085794Z","iopub.status.idle":"2022-12-14T06:40:53.195150Z","shell.execute_reply.started":"2022-12-14T06:40:53.085758Z","shell.execute_reply":"2022-12-14T06:40:53.194211Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:53.196847Z","iopub.execute_input":"2022-12-14T06:40:53.197261Z","iopub.status.idle":"2022-12-14T06:40:53.205553Z","shell.execute_reply.started":"2022-12-14T06:40:53.197210Z","shell.execute_reply":"2022-12-14T06:40:53.204350Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 62, 62, 25)        700       \n_________________________________________________________________\nactivation (Activation)      (None, 62, 62, 25)        0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 31, 25)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 29, 29, 32)        7232      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 29, 29, 32)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6272)              0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                401472    \n_________________________________________________________________\nactivation_2 (Activation)    (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                4160      \n_________________________________________________________________\nactivation_3 (Activation)    (None, 64)                0         \n_________________________________________________________________\ndropout (Dropout)            (None, 64)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 65        \n_________________________________________________________________\nactivation_4 (Activation)    (None, 1)                 0         \n=================================================================\nTotal params: 413,629\nTrainable params: 413,629\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-12-14T06:40:53.207403Z","iopub.execute_input":"2022-12-14T06:40:53.208818Z","iopub.status.idle":"2022-12-14T06:43:16.277317Z","shell.execute_reply.started":"2022-12-14T06:40:53.208778Z","shell.execute_reply":"2022-12-14T06:43:16.276073Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2022-12-14 06:40:53.910045: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-12-14 06:41:04.115680: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 83 of 1000\n2022-12-14 06:41:14.182481: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 173 of 1000\n2022-12-14 06:41:24.115980: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 435 of 1000\n2022-12-14 06:41:24.737020: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n2022-12-14 06:41:26.144706: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"498/498 [==============================] - 52s 23ms/step - loss: -505.9246 - accuracy: 0.5448 - val_loss: -5767.5679 - val_accuracy: 0.5384\nEpoch 2/10\n498/498 [==============================] - 10s 11ms/step - loss: -132492.7344 - accuracy: 0.5434 - val_loss: -648228.8125 - val_accuracy: 0.5384\nEpoch 3/10\n498/498 [==============================] - 11s 11ms/step - loss: -2286822.0000 - accuracy: 0.5437 - val_loss: -5980696.5000 - val_accuracy: 0.5384\nEpoch 4/10\n498/498 [==============================] - 10s 10ms/step - loss: -12562459.0000 - accuracy: 0.5393 - val_loss: -24006374.0000 - val_accuracy: 0.5384\nEpoch 5/10\n498/498 [==============================] - 10s 11ms/step - loss: -44776716.0000 - accuracy: 0.5431 - val_loss: -60115564.0000 - val_accuracy: 0.5384\nEpoch 6/10\n498/498 [==============================] - 10s 10ms/step - loss: -103008288.0000 - accuracy: 0.5399 - val_loss: -154293184.0000 - val_accuracy: 0.5384\nEpoch 7/10\n498/498 [==============================] - 9s 9ms/step - loss: -216653536.0000 - accuracy: 0.5412 - val_loss: -290732352.0000 - val_accuracy: 0.5384\nEpoch 8/10\n498/498 [==============================] - 9s 10ms/step - loss: -381000288.0000 - accuracy: 0.5427 - val_loss: -535942720.0000 - val_accuracy: 0.5384\nEpoch 9/10\n498/498 [==============================] - 10s 9ms/step - loss: -641678400.0000 - accuracy: 0.5431 - val_loss: -947014080.0000 - val_accuracy: 0.5384\nEpoch 10/10\n498/498 [==============================] - 9s 9ms/step - loss: -1066142400.0000 - accuracy: 0.5413 - val_loss: -1354767104.0000 - val_accuracy: 0.5384\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}