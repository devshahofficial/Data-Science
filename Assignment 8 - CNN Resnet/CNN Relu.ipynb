{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-30T20:08:55.489482Z","iopub.execute_input":"2022-11-30T20:08:55.489816Z","iopub.status.idle":"2022-11-30T20:08:55.516806Z","shell.execute_reply.started":"2022-11-30T20:08:55.489744Z","shell.execute_reply":"2022-11-30T20:08:55.515797Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cifar-10/trainLabels.csv\n/kaggle/input/cifar-10/sampleSubmission.csv\n/kaggle/input/cifar-10/test.7z\n/kaggle/input/cifar-10/train.7z\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install py7zr # for unzipping data","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:08:55.518619Z","iopub.execute_input":"2022-11-30T20:08:55.519265Z","iopub.status.idle":"2022-11-30T20:09:10.419776Z","shell.execute_reply.started":"2022-11-30T20:08:55.519229Z","shell.execute_reply":"2022-11-30T20:09:10.418503Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting py7zr\n  Downloading py7zr-0.20.2-py3-none-any.whl (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m734.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting pybcj>=0.6.0\n  Downloading pybcj-1.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1\n  Downloading pyppmd-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.6/138.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting inflate64>=0.3.1\n  Downloading inflate64-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: texttable in /opt/conda/lib/python3.7/site-packages (from py7zr) (1.6.4)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from py7zr) (4.13.0)\nCollecting pyzstd>=0.14.4\n  Downloading pyzstd-0.15.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.2/379.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from py7zr) (5.9.1)\nCollecting pycryptodomex>=3.6.6\n  Downloading pycryptodomex-3.16.0-cp35-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting multivolumefile>=0.2.3\n  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nCollecting brotli>=1.0.9\n  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (3.8.0)\nInstalling collected packages: brotli, pyzstd, pyppmd, pycryptodomex, multivolumefile, pybcj, inflate64, py7zr\nSuccessfully installed brotli-1.0.9 inflate64-0.3.1 multivolumefile-0.2.3 py7zr-0.20.2 pybcj-1.0.1 pycryptodomex-3.16.0 pyppmd-1.0.0 pyzstd-0.15.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from py7zr import unpack_7zarchive\nimport shutil\nshutil.register_unpack_format('7zip',['.7z'],unpack_7zarchive)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:09:10.422714Z","iopub.execute_input":"2022-11-30T20:09:10.423359Z","iopub.status.idle":"2022-11-30T20:09:10.568737Z","shell.execute_reply.started":"2022-11-30T20:09:10.423316Z","shell.execute_reply":"2022-11-30T20:09:10.567841Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"shutil.unpack_archive('../input/cifar-10/train.7z', '/kaggle/temp/')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:09:10.571097Z","iopub.execute_input":"2022-11-30T20:09:10.571561Z","iopub.status.idle":"2022-11-30T20:09:56.528548Z","shell.execute_reply.started":"2022-11-30T20:09:10.571524Z","shell.execute_reply":"2022-11-30T20:09:56.527478Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv(\"../input/cifar-10/trainLabels.csv\", header=\"infer\")\n\nclasses = labels['label'].unique()\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:09:56.530096Z","iopub.execute_input":"2022-11-30T20:09:56.531074Z","iopub.status.idle":"2022-11-30T20:09:56.604994Z","shell.execute_reply.started":"2022-11-30T20:09:56.531035Z","shell.execute_reply":"2022-11-30T20:09:56.604232Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['frog' 'truck' 'deer' 'automobile' 'bird' 'horse' 'ship' 'cat' 'dog'\n 'airplane']\n","output_type":"stream"}]},{"cell_type":"code","source":"if not os.path.exists(\"/kaggle/temp/valid\"):\n    os.mkdir(\"/kaggle/temp/valid\")\n    \nparent_path_train = \"/kaggle/temp/train\"\nparent_path_valid = \"/kaggle/temp/valid\"\nparent_path_test = \"/kaggle/temp/test\"\n\nfor class1 in classes:\n    path_train = os.path.join(parent_path_train,class1)\n    if not os.path.exists(path_train):\n        os.mkdir(path_train)\n    path_valid = os.path.join(parent_path_valid,class1)\n    if not os.path.exists(path_valid):\n        os.mkdir(path_valid)\n        \nfor (int_ind,row) in labels.iterrows():\n    id = str(row[\"id\"])+\".png\"\n    source_path = os.path.join(parent_path_train,id)\n    \n    p=np.random.random()\n    if p<=0.8:\n        target_path = os.path.join(parent_path_train,row[\"label\"],id)\n        os.replace(source_path, target_path)\n    else:\n        target_path = os.path.join(parent_path_valid,row[\"label\"],id)\n        os.replace(source_path, target_path)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:09:56.606481Z","iopub.execute_input":"2022-11-30T20:09:56.606843Z","iopub.status.idle":"2022-11-30T20:10:02.527398Z","shell.execute_reply.started":"2022-11-30T20:09:56.606808Z","shell.execute_reply":"2022-11-30T20:10:02.526271Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nimport os\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Dense, Dropout, Activation,Flatten,Conv2D,MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.datasets import cifar10 \nimport warnings\nwarnings.filterwarnings('ignore')\n\ntf.__version__\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:10:02.528827Z","iopub.execute_input":"2022-11-30T20:10:02.529173Z","iopub.status.idle":"2022-11-30T20:10:08.445118Z","shell.execute_reply.started":"2022-11-30T20:10:02.529139Z","shell.execute_reply":"2022-11-30T20:10:08.444182Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add( Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False, input_shape=(32,32,3)) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=48, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=80, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=112, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=144, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=160, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add( Conv2D(filters=176, kernel_size=(3,3), strides=(1,1), padding='valid', activation=None, use_bias=False) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units=10))\nmodel.add(BatchNormalization())\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:10:08.446439Z","iopub.execute_input":"2022-11-30T20:10:08.447139Z","iopub.status.idle":"2022-11-30T20:10:11.533504Z","shell.execute_reply.started":"2022-11-30T20:10:08.447100Z","shell.execute_reply":"2022-11-30T20:10:11.532591Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2022-11-30 20:10:08.555952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:08.656961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:08.657772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:08.658949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-30 20:10:08.659308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:08.660152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:08.660897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:10.934959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:10.935925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:10.936612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-30 20:10:10.937189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(featurewise_center=False,\n                             samplewise_center=False,\n                             featurewise_std_normalization=False,\n                             samplewise_std_normalization=False,\n                             zca_whitening=False,\n                             rotation_range=10,\n                             zoom_range=0.1,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             horizontal_flip=False,\n                             vertical_flip=False,\n                             rescale=1./255)\nvalid_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_directory(directory='/kaggle/temp/train/', shuffle=True, target_size=(32,32),batch_size=128)\nvalid_generator = valid_datagen.flow_from_directory(directory='/kaggle/temp/valid/', shuffle=True, target_size=(32,32),batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:10:11.536551Z","iopub.execute_input":"2022-11-30T20:10:11.536893Z","iopub.status.idle":"2022-11-30T20:10:12.657145Z","shell.execute_reply.started":"2022-11-30T20:10:11.536859Z","shell.execute_reply":"2022-11-30T20:10:12.656066Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 39899 images belonging to 10 classes.\nFound 10101 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    train_generator,\n    epochs=20,\n    validation_data=valid_generator,\n    steps_per_epoch=train_generator.n//train_generator.batch_size,\n    validation_steps= valid_generator.n//valid_generator.batch_size,\n    workers=8,\n    use_multiprocessing=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:10:12.658776Z","iopub.execute_input":"2022-11-30T20:10:12.659153Z","iopub.status.idle":"2022-11-30T20:22:46.197245Z","shell.execute_reply.started":"2022-11-30T20:10:12.659116Z","shell.execute_reply":"2022-11-30T20:22:46.195969Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2022-11-30 20:10:12.848309: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2022-11-30 20:10:15.633698: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"311/311 [==============================] - 41s 104ms/step - loss: 1.5932 - accuracy: 0.4359 - val_loss: 48.8439 - val_accuracy: 0.1038\nEpoch 2/20\n311/311 [==============================] - 33s 102ms/step - loss: 1.2585 - accuracy: 0.5709 - val_loss: 135.5498 - val_accuracy: 0.1017\nEpoch 3/20\n311/311 [==============================] - 33s 102ms/step - loss: 1.0935 - accuracy: 0.6303 - val_loss: 59.3857 - val_accuracy: 0.2067\nEpoch 4/20\n311/311 [==============================] - 33s 104ms/step - loss: 0.9839 - accuracy: 0.6679 - val_loss: 66.8733 - val_accuracy: 0.1738\nEpoch 5/20\n311/311 [==============================] - 33s 102ms/step - loss: 0.8900 - accuracy: 0.7013 - val_loss: 34.6101 - val_accuracy: 0.2014\nEpoch 6/20\n311/311 [==============================] - 34s 106ms/step - loss: 0.8238 - accuracy: 0.7218 - val_loss: 63.1435 - val_accuracy: 0.1620\nEpoch 7/20\n311/311 [==============================] - 33s 105ms/step - loss: 0.7706 - accuracy: 0.7410 - val_loss: 46.2205 - val_accuracy: 0.1622\nEpoch 8/20\n311/311 [==============================] - 34s 105ms/step - loss: 0.7179 - accuracy: 0.7582 - val_loss: 40.9025 - val_accuracy: 0.1573\nEpoch 9/20\n311/311 [==============================] - 35s 107ms/step - loss: 0.6841 - accuracy: 0.7692 - val_loss: 52.2183 - val_accuracy: 0.1379\nEpoch 10/20\n311/311 [==============================] - 33s 104ms/step - loss: 0.6428 - accuracy: 0.7819 - val_loss: 47.0560 - val_accuracy: 0.1251\nEpoch 11/20\n311/311 [==============================] - 33s 104ms/step - loss: 0.6075 - accuracy: 0.7956 - val_loss: 37.1670 - val_accuracy: 0.1296\nEpoch 12/20\n311/311 [==============================] - 33s 102ms/step - loss: 0.5797 - accuracy: 0.8060 - val_loss: 54.4294 - val_accuracy: 0.1503\nEpoch 13/20\n311/311 [==============================] - 33s 104ms/step - loss: 0.5558 - accuracy: 0.8118 - val_loss: 36.0327 - val_accuracy: 0.1259\nEpoch 14/20\n311/311 [==============================] - 33s 104ms/step - loss: 0.5323 - accuracy: 0.8205 - val_loss: 65.6906 - val_accuracy: 0.1212\nEpoch 15/20\n311/311 [==============================] - 33s 102ms/step - loss: 0.5120 - accuracy: 0.8278 - val_loss: 49.2648 - val_accuracy: 0.1711\nEpoch 16/20\n311/311 [==============================] - 35s 109ms/step - loss: 0.4885 - accuracy: 0.8340 - val_loss: 66.8299 - val_accuracy: 0.1072\nEpoch 17/20\n311/311 [==============================] - 32s 101ms/step - loss: 0.4718 - accuracy: 0.8417 - val_loss: 48.1609 - val_accuracy: 0.1459\nEpoch 18/20\n311/311 [==============================] - 33s 102ms/step - loss: 0.4502 - accuracy: 0.8469 - val_loss: 43.8364 - val_accuracy: 0.1521\nEpoch 19/20\n311/311 [==============================] - 33s 102ms/step - loss: 0.4327 - accuracy: 0.8538 - val_loss: 42.3750 - val_accuracy: 0.1166\nEpoch 20/20\n311/311 [==============================] - 33s 102ms/step - loss: 0.4212 - accuracy: 0.8556 - val_loss: 47.1088 - val_accuracy: 0.1275\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f387c6336d0>"},"metadata":{}}]},{"cell_type":"code","source":"shutil.unpack_archive('/kaggle/input/cifar-10/test.7z','/kaggle/temp/test')\nshutil.unregister_unpack_format('7zip')","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:22:46.200168Z","iopub.execute_input":"2022-11-30T20:22:46.200643Z","iopub.status.idle":"2022-11-30T20:36:36.896927Z","shell.execute_reply.started":"2022-11-30T20:22:46.200595Z","shell.execute_reply":"2022-11-30T20:36:36.895860Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_gen = test_datagen.flow_from_directory(directory='/kaggle/temp/test',target_size=(32,32),batch_size=64,class_mode=None,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:36:36.898280Z","iopub.execute_input":"2022-11-30T20:36:36.899258Z","iopub.status.idle":"2022-11-30T20:36:42.936052Z","shell.execute_reply.started":"2022-11-30T20:36:36.899219Z","shell.execute_reply":"2022-11-30T20:36:42.934968Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 300000 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_gen.reset()\npredictions_vecs = model.predict(test_gen)\n\npredictions_final = np.argmax(predictions_vecs, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:38:10.506365Z","iopub.execute_input":"2022-11-30T20:38:10.506757Z","iopub.status.idle":"2022-11-30T20:39:42.078519Z","shell.execute_reply.started":"2022-11-30T20:38:10.506726Z","shell.execute_reply":"2022-11-30T20:39:42.077521Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(type(train_generator.class_indices))\nprint(train_generator.class_indices)\n\nclasses = {value:key for (key,value) in train_generator.class_indices.items()}\nprint(classes)\n\npredicted_classes=np.empty(shape=300000,dtype=np.dtype('U20'))\n\nind=0\nfor i in predictions_final.tolist():\n    predicted_classes[ind]=classes[i]\n    ind=ind+1\n    \nfilenames_wo_ext = []\nfor fname in test_gen.filenames:\n    filenames_wo_ext.append(int(fname.split(sep=\"/\")[1].split(sep=\".\")[0])-1)\n\npredicted_classes_final = np.empty(shape=300000,dtype=np.dtype('U20'))\npredicted_classes_final[filenames_wo_ext]=predicted_classes","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:39:42.080490Z","iopub.execute_input":"2022-11-30T20:39:42.080897Z","iopub.status.idle":"2022-11-30T20:39:42.462862Z","shell.execute_reply.started":"2022-11-30T20:39:42.080862Z","shell.execute_reply":"2022-11-30T20:39:42.461934Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<class 'dict'>\n{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n","output_type":"stream"}]},{"cell_type":"code","source":"sub = pd.read_csv('../input/cifar-10/sampleSubmission.csv',header='infer')\nsub.info()\nsub['label'] = predicted_classes_final\nsub.to_csv('submission.csv',index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:39:42.464405Z","iopub.execute_input":"2022-11-30T20:39:42.464816Z","iopub.status.idle":"2022-11-30T20:39:42.952663Z","shell.execute_reply.started":"2022-11-30T20:39:42.464779Z","shell.execute_reply":"2022-11-30T20:39:42.951721Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 300000 entries, 0 to 299999\nData columns (total 2 columns):\n #   Column  Non-Null Count   Dtype \n---  ------  --------------   ----- \n 0   id      300000 non-null  int64 \n 1   label   300000 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 4.6+ MB\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"            id       label\n0            1       truck\n1            2    airplane\n2            3  automobile\n3            4        ship\n4            5    airplane\n...        ...         ...\n299995  299996       truck\n299996  299997        frog\n299997  299998       horse\n299998  299999       horse\n299999  300000  automobile\n\n[300000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>truck</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>automobile</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>ship</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>299996</td>\n      <td>truck</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>299997</td>\n      <td>frog</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>299998</td>\n      <td>horse</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>299999</td>\n      <td>horse</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>300000</td>\n      <td>automobile</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T20:39:42.954911Z","iopub.execute_input":"2022-11-30T20:39:42.955277Z","iopub.status.idle":"2022-11-30T20:39:42.964874Z","shell.execute_reply.started":"2022-11-30T20:39:42.955241Z","shell.execute_reply":"2022-11-30T20:39:42.963766Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 30, 30, 32)        864       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 30, 30, 32)        128       \n_________________________________________________________________\nactivation (Activation)      (None, 30, 30, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 28, 28, 48)        13824     \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 28, 28, 48)        192       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 28, 28, 48)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 26, 26, 64)        27648     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 26, 26, 64)        256       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 26, 26, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 24, 24, 80)        46080     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 24, 24, 80)        320       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 24, 24, 80)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 22, 22, 96)        69120     \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 22, 22, 96)        384       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 22, 22, 96)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 20, 20, 112)       96768     \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 20, 20, 112)       448       \n_________________________________________________________________\nactivation_5 (Activation)    (None, 20, 20, 112)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 18, 18, 128)       129024    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 18, 18, 128)       512       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 18, 18, 128)       0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 16, 16, 144)       165888    \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 16, 16, 144)       576       \n_________________________________________________________________\nactivation_7 (Activation)    (None, 16, 16, 144)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 14, 14, 160)       207360    \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 14, 14, 160)       640       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 14, 14, 160)       0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 12, 12, 176)       253440    \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 12, 12, 176)       704       \n_________________________________________________________________\nactivation_9 (Activation)    (None, 12, 12, 176)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25344)             0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                253450    \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 10)                40        \n_________________________________________________________________\nactivation_10 (Activation)   (None, 10)                0         \n=================================================================\nTotal params: 1,267,666\nTrainable params: 1,265,566\nNon-trainable params: 2,100\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}