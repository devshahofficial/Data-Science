{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study the decision tree algorithm,\n",
    "# focusing on both entropy based information\n",
    "# gain and Gini index for splitting. Build\n",
    "# decision trees and random forests for the loan\n",
    "# datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all necessary imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Sex        Age  Time_at_address Res_status  Telephone Occupation Job_status  \\\n0   M  50.750000            0.585      owner      given  unemploye  unemploye   \n1   M  19.670000           10.000       rent  not_given   labourer  governmen   \n2   F  52.830002           15.000      owner      given  creative_  private_s   \n3   M  22.670000            2.540       rent  not_given  creative_  governmen   \n4   M  29.250000           13.000      owner      given     driver  governmen   \n\n   Time_employed  Time_bank Liab_ref Acc_ref  Home_Expn  Balance Decision  \n0              0          0        f   given        145        0   reject  \n1              0          0        t   given        140        0   reject  \n2              5         14        f   given          0     2200   accept  \n3              2          0        f   given          0        0   accept  \n4              0          0        f   given        228        0   reject  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Time_at_address</th>\n      <th>Res_status</th>\n      <th>Telephone</th>\n      <th>Occupation</th>\n      <th>Job_status</th>\n      <th>Time_employed</th>\n      <th>Time_bank</th>\n      <th>Liab_ref</th>\n      <th>Acc_ref</th>\n      <th>Home_Expn</th>\n      <th>Balance</th>\n      <th>Decision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>50.750000</td>\n      <td>0.585</td>\n      <td>owner</td>\n      <td>given</td>\n      <td>unemploye</td>\n      <td>unemploye</td>\n      <td>0</td>\n      <td>0</td>\n      <td>f</td>\n      <td>given</td>\n      <td>145</td>\n      <td>0</td>\n      <td>reject</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>19.670000</td>\n      <td>10.000</td>\n      <td>rent</td>\n      <td>not_given</td>\n      <td>labourer</td>\n      <td>governmen</td>\n      <td>0</td>\n      <td>0</td>\n      <td>t</td>\n      <td>given</td>\n      <td>140</td>\n      <td>0</td>\n      <td>reject</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>52.830002</td>\n      <td>15.000</td>\n      <td>owner</td>\n      <td>given</td>\n      <td>creative_</td>\n      <td>private_s</td>\n      <td>5</td>\n      <td>14</td>\n      <td>f</td>\n      <td>given</td>\n      <td>0</td>\n      <td>2200</td>\n      <td>accept</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>22.670000</td>\n      <td>2.540</td>\n      <td>rent</td>\n      <td>not_given</td>\n      <td>creative_</td>\n      <td>governmen</td>\n      <td>2</td>\n      <td>0</td>\n      <td>f</td>\n      <td>given</td>\n      <td>0</td>\n      <td>0</td>\n      <td>accept</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>29.250000</td>\n      <td>13.000</td>\n      <td>owner</td>\n      <td>given</td>\n      <td>driver</td>\n      <td>governmen</td>\n      <td>0</td>\n      <td>0</td>\n      <td>f</td>\n      <td>given</td>\n      <td>228</td>\n      <td>0</td>\n      <td>reject</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel('loan.xlsx')\n",
    "new_dataset = dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              Age  Time_at_address  Time_employed   Time_bank   Home_Expn  \\\ncount  429.000000       429.000000     429.000000  429.000000  429.000000   \nmean    31.510163         4.650758       1.871795    2.279720  176.727273   \nstd     11.843595         4.804037       3.254023    3.966105  142.590659   \nmin     15.170000         0.000000       0.000000    0.000000    0.000000   \n25%     22.670000         1.000000       0.000000    0.000000   80.000000   \n50%     28.500000         2.750000       1.000000    0.000000  160.000000   \n75%     38.250000         7.000000       2.000000    3.000000  272.000000   \nmax     76.750000        25.209999      20.000000   23.000000  760.000000   \n\n            Balance  \ncount    429.000000  \nmean     898.382284  \nstd     3814.565340  \nmin        0.000000  \n25%        0.000000  \n50%       10.000000  \n75%      484.000000  \nmax    51100.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Time_at_address</th>\n      <th>Time_employed</th>\n      <th>Time_bank</th>\n      <th>Home_Expn</th>\n      <th>Balance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>429.000000</td>\n      <td>429.000000</td>\n      <td>429.000000</td>\n      <td>429.000000</td>\n      <td>429.000000</td>\n      <td>429.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>31.510163</td>\n      <td>4.650758</td>\n      <td>1.871795</td>\n      <td>2.279720</td>\n      <td>176.727273</td>\n      <td>898.382284</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11.843595</td>\n      <td>4.804037</td>\n      <td>3.254023</td>\n      <td>3.966105</td>\n      <td>142.590659</td>\n      <td>3814.565340</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>15.170000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>22.670000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>28.500000</td>\n      <td>2.750000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>160.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>38.250000</td>\n      <td>7.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>272.000000</td>\n      <td>484.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>76.750000</td>\n      <td>25.209999</td>\n      <td>20.000000</td>\n      <td>23.000000</td>\n      <td>760.000000</td>\n      <td>51100.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing for loan.xlsx file was done\n",
    "# in the previous assignment. The reference for preprocessing\n",
    "# has been taken from the previous assignment\n",
    "\n",
    "# dataset summary\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Sex                0\nAge                0\nTime_at_address    0\nRes_status         0\nTelephone          0\nOccupation         0\nJob_status         0\nTime_employed      0\nTime_bank          0\nLiab_ref           0\nAcc_ref            0\nHome_Expn          0\nBalance            0\nDecision           0\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding out null data => missing data\n",
    "dataset.isnull().sum()\n",
    "\n",
    "# inference => no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(429, 14)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape\n",
    "\n",
    "# before calculating correlation, we shall one. hot encode Sex, Res_Status, Telephone, Occupation, Job Status, Acc_ref, Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# label encoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex:  2\n"
     ]
    }
   ],
   "source": [
    "# sex\n",
    "print('Sex: ', dataset['Sex'].nunique())\n",
    "\n",
    "new_dataset['Sex'] = label_encoder.fit_transform(dataset['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res_status:  2\n"
     ]
    }
   ],
   "source": [
    "# Res_Status\n",
    "print('Res_status: ', dataset['Res_status'].nunique())\n",
    "\n",
    "dataset['Res_status'] = label_encoder.fit_transform(dataset['Res_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telephone:  2\n"
     ]
    }
   ],
   "source": [
    "# Telephone\n",
    "print('Telephone: ', dataset['Telephone'].nunique())\n",
    "\n",
    "dataset['Telephone'] = label_encoder.fit_transform(dataset['Telephone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc_ref:  2\n"
     ]
    }
   ],
   "source": [
    "# Acc_ref\n",
    "print('Acc_ref: ', dataset['Acc_ref'].nunique())\n",
    "\n",
    "dataset['Acc_ref'] = label_encoder.fit_transform(dataset['Acc_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liab_ref:  2\n"
     ]
    }
   ],
   "source": [
    "# Liab_ref\n",
    "print('Liab_ref: ', dataset['Liab_ref'].nunique())\n",
    "\n",
    "dataset['Liab_ref'] = label_encoder.fit_transform(dataset['Liab_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "Decision:  2\n"
     ]
    }
   ],
   "source": [
    "# Decision\n",
    "print(dataset['Decision'].dtype)\n",
    "print('Decision: ', dataset['Decision'].nunique())\n",
    "\n",
    "dataset['Decision'] = label_encoder.fit_transform(dataset['Decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job_status:  ['unemploye' 'governmen' 'private_s' 'self_empl' 'retired' 'student'\n",
      " 'military']\n"
     ]
    }
   ],
   "source": [
    "# Job_status\n",
    "\n",
    "print('Job_status: ', dataset['Job_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation:  ['unemploye' 'labourer' 'creative_' 'driver' 'professio' 'manager'\n",
      " 'guard_etc' 'executive' 'office_st' 'productio' 'semi_pro' 'sales']\n"
     ]
    }
   ],
   "source": [
    "# Occupation\n",
    "print('Occupation: ', dataset['Occupation'].unique())\n",
    "\n",
    "# dataset['Occupation'] = label_encoder.fit_transform(dataset['Res_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_array = onehot_encoder.fit_transform(dataset[['Job_status', 'Occupation']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['governmen',\n 'military',\n 'private_s',\n 'retired',\n 'self_empl',\n 'student',\n 'unemploye',\n 'creative_',\n 'driver',\n 'executive',\n 'guard_etc',\n 'labourer',\n 'manager',\n 'office_st',\n 'productio',\n 'professio',\n 'sales',\n 'semi_pro',\n 'unemploye']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_labels = ['governmen', 'military', 'private_s', 'retired', 'self_empl',\n",
    "        'student', 'unemploye', 'creative_', 'driver', 'executive', 'guard_etc', 'labourer',\n",
    "        'manager', 'office_st', 'productio', 'professio', 'sales',\n",
    "        'semi_pro', 'unemploye']\n",
    "feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(features_array, columns = feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['Occupation','Job_status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Sex', 'Age', 'Time_at_address', 'Res_status', 'Telephone',\n       'Time_employed', 'Time_bank', 'Liab_ref', 'Acc_ref', 'Home_Expn',\n       'Balance', 'Decision', 'governmen', 'military', 'private_s', 'retired',\n       'self_empl', 'student', 'unemploye', 'creative_', 'driver', 'executive',\n       'guard_etc', 'labourer', 'manager', 'office_st', 'productio',\n       'professio', 'sales', 'semi_pro', 'unemploye'],\n      dtype='object')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                      Sex       Age  Time_at_address  Res_status  Telephone  \\\nSex              1.000000  0.025167        -0.031594    0.121713   0.121713   \nAge              0.025167  1.000000         0.217342   -0.080265  -0.080265   \nTime_at_address -0.031594  0.217342         1.000000   -0.100614  -0.100614   \nRes_status       0.121713 -0.080265        -0.100614    1.000000   1.000000   \nTelephone        0.121713 -0.080265        -0.100614    1.000000   1.000000   \nTime_employed    0.077239  0.426890         0.278849   -0.074690  -0.074690   \nTime_bank       -0.072303  0.208736         0.202083   -0.132413  -0.132413   \nLiab_ref         0.010508  0.049109        -0.049978    0.018827   0.018827   \nAcc_ref          0.095826 -0.040445        -0.144258   -0.000201  -0.000201   \nHome_Expn        0.115355 -0.072254        -0.267470   -0.006477  -0.006477   \nBalance         -0.045248  0.101819         0.072235   -0.068829  -0.068829   \nDecision         0.052564 -0.181241        -0.163298    0.139104   0.139104   \ngovernmen       -0.071354  0.011700         0.032959    0.006508   0.006508   \nmilitary         0.033287 -0.054508        -0.022068   -0.026127  -0.026127   \nprivate_s        0.043589 -0.247584        -0.083958   -0.021999  -0.021999   \nretired          0.021153  0.309407         0.271421   -0.033319  -0.033319   \nself_empl        0.087138  0.114273        -0.058537   -0.007264  -0.007264   \nstudent         -0.018208 -0.076762         0.030354    0.045143   0.045143   \nunemploye       -0.077631  0.203320         0.020707    0.042843   0.042843   \ncreative_        0.092333 -0.100224        -0.043791    0.029843   0.029843   \ndriver           0.056538 -0.061793         0.036117    0.011242   0.011242   \nexecutive        0.033932  0.195693         0.194672   -0.013801  -0.013801   \nguard_etc        0.022947  0.028675        -0.074592   -0.059316  -0.059316   \nlabourer        -0.008220 -0.035318        -0.027105    0.103196   0.103196   \nmanager          0.141564  0.056127        -0.062565   -0.007468  -0.007468   \noffice_st       -0.239058 -0.085265         0.060743   -0.141542  -0.141542   \nproductio        0.089171 -0.025142         0.007001    0.015006   0.015006   \nprofessio       -0.028788 -0.008012        -0.023361    0.058154   0.058154   \nsales           -0.116177 -0.061906         0.018662   -0.043244  -0.043244   \nsemi_pro         0.057602 -0.002900        -0.069254    0.012631   0.012631   \nunemploye       -0.085110  0.210038         0.028853    0.048437   0.048437   \n\n                 Time_employed  Time_bank  Liab_ref   Acc_ref  Home_Expn  ...  \\\nSex                   0.077239  -0.072303  0.010508  0.095826   0.115355  ...   \nAge                   0.426890   0.208736  0.049109 -0.040445  -0.072254  ...   \nTime_at_address       0.278849   0.202083 -0.049978 -0.144258  -0.267470  ...   \nRes_status           -0.074690  -0.132413  0.018827 -0.000201  -0.006477  ...   \nTelephone            -0.074690  -0.132413  0.018827 -0.000201  -0.006477  ...   \nTime_employed         1.000000   0.291542  0.122561 -0.025000  -0.110933  ...   \nTime_bank             0.291542   1.000000  0.051000 -0.158334  -0.111761  ...   \nLiab_ref              0.122561   0.051000  1.000000  0.033197   0.127133  ...   \nAcc_ref              -0.025000  -0.158334  0.033197  1.000000   0.096426  ...   \nHome_Expn            -0.110933  -0.111761  0.127133  0.096426   1.000000  ...   \nBalance               0.112719   0.153435 -0.013128 -0.065739   0.080366  ...   \nDecision             -0.339833  -0.455942 -0.068508  0.106354   0.087311  ...   \ngovernmen             0.135908   0.097365 -0.041223 -0.066981   0.059496  ...   \nmilitary             -0.027837  -0.003413  0.052702 -0.013490  -0.005677  ...   \nprivate_s            -0.172712  -0.115185  0.037822  0.089868   0.035104  ...   \nretired               0.265212   0.155554 -0.022658 -0.038472  -0.149999  ...   \nself_empl             0.045330   0.030708  0.084938  0.010466   0.076962  ...   \nstudent              -0.042492  -0.035080 -0.012399 -0.030307  -0.043405  ...   \nunemploye            -0.047159  -0.031069 -0.093314 -0.043119  -0.142259  ...   \ncreative_            -0.005600   0.103602 -0.034575 -0.036148  -0.088680  ...   \ndriver               -0.064149  -0.085321  0.041735  0.135115  -0.032013  ...   \nexecutive             0.158402   0.070908 -0.047445  0.023691  -0.022788  ...   \nguard_etc            -0.048504  -0.079085  0.051444 -0.017403   0.070586  ...   \nlabourer             -0.076296  -0.102461  0.044265  0.029235  -0.024372  ...   \nmanager               0.085916  -0.004365  0.041821  0.254292   0.121765  ...   \noffice_st             0.045731   0.115238 -0.005693 -0.071914  -0.017424  ...   \nproductio            -0.005221  -0.035694  0.037271 -0.036777   0.048673  ...   \nprofessio             0.065455   0.030341  0.030484 -0.063317   0.112318  ...   \nsales                -0.080398  -0.087884 -0.057168 -0.077889  -0.049655  ...   \nsemi_pro              0.001919   0.042998 -0.003053 -0.019012   0.094591  ...   \nunemploye            -0.042615  -0.026283 -0.086354 -0.041226  -0.139506  ...   \n\n                 executive  guard_etc  labourer   manager  office_st  \\\nSex               0.033932   0.022947 -0.008220  0.141564  -0.239058   \nAge               0.195693   0.028675 -0.035318  0.056127  -0.085265   \nTime_at_address   0.194672  -0.074592 -0.027105 -0.062565   0.060743   \nRes_status       -0.013801  -0.059316  0.103196 -0.007468  -0.141542   \nTelephone        -0.013801  -0.059316  0.103196 -0.007468  -0.141542   \nTime_employed     0.158402  -0.048504 -0.076296  0.085916   0.045731   \nTime_bank         0.070908  -0.079085 -0.102461 -0.004365   0.115238   \nLiab_ref         -0.047445   0.051444  0.044265  0.041821  -0.005693   \nAcc_ref           0.023691  -0.017403  0.029235  0.254292  -0.071914   \nHome_Expn        -0.022788   0.070586 -0.024372  0.121765  -0.017424   \nBalance           0.153182  -0.025923 -0.053978 -0.023879  -0.008416   \nDecision         -0.067796   0.131258  0.107222  0.029066  -0.133674   \ngovernmen        -0.079377  -0.036600  0.019390 -0.080452   0.179558   \nmilitary         -0.010689  -0.014407 -0.015924 -0.012773  -0.017357   \nprivate_s        -0.190084  -0.203628  0.081608  0.130195  -0.004043   \nretired           0.623377  -0.041086 -0.045412 -0.036426  -0.049501   \nself_empl         0.010833   0.515114 -0.073270 -0.013948  -0.110322   \nstudent           0.491076  -0.032366 -0.035774 -0.028695  -0.038995   \nunemploye        -0.061715  -0.083181 -0.061647 -0.073747  -0.100218   \ncreative_        -0.115540  -0.155727 -0.172127 -0.138066  -0.187623   \ndriver           -0.043525  -0.058664 -0.064842 -0.052011  -0.070679   \nexecutive         1.000000  -0.065908 -0.072849 -0.058433  -0.079407   \nguard_etc        -0.065908   1.000000 -0.098187 -0.078758  -0.107027   \nlabourer         -0.072849  -0.098187  1.000000 -0.087051  -0.118297   \nmanager          -0.058433  -0.078758 -0.087051  1.000000  -0.094888   \noffice_st        -0.079407  -0.107027 -0.118297 -0.094888   1.000000   \nproductio        -0.075700  -0.102030 -0.112774 -0.090458  -0.122927   \nprofessio        -0.050169  -0.067618 -0.074739 -0.059950  -0.081468   \nsales            -0.061715  -0.083181 -0.091941 -0.073747  -0.100218   \nsemi_pro         -0.048900  -0.065908 -0.072849 -0.058433  -0.079407   \nunemploye        -0.060636  -0.081726 -0.090332 -0.072457  -0.098465   \n\n                 productio  professio     sales  semi_pro  unemploye  \nSex               0.089171  -0.028788 -0.116177  0.057602  -0.085110  \nAge              -0.025142  -0.008012 -0.061906 -0.002900   0.210038  \nTime_at_address   0.007001  -0.023361  0.018662 -0.069254   0.028853  \nRes_status        0.015006   0.058154 -0.043244  0.012631   0.048437  \nTelephone         0.015006   0.058154 -0.043244  0.012631   0.048437  \nTime_employed    -0.005221   0.065455 -0.080398  0.001919  -0.042615  \nTime_bank        -0.035694   0.030341 -0.087884  0.042998  -0.026283  \nLiab_ref          0.037271   0.030484 -0.057168 -0.003053  -0.086354  \nAcc_ref          -0.036777  -0.063317 -0.077889 -0.019012  -0.041226  \nHome_Expn         0.048673   0.112318 -0.049655  0.094591  -0.139506  \nBalance          -0.028536   0.004505 -0.028959  0.138420  -0.020692  \nDecision         -0.028458  -0.165153  0.033932 -0.134504   0.173276  \ngovernmen        -0.050329   0.191944 -0.089877  0.117460  -0.133296  \nmilitary         -0.016547  -0.010966 -0.013490 -0.010689  -0.013254  \nprivate_s         0.175375  -0.066073  0.163973 -0.030814  -0.348558  \nretired          -0.047189  -0.031274 -0.038472 -0.030483  -0.037799  \nself_empl        -0.105172  -0.069701 -0.053673 -0.028552  -0.084243  \nstudent          -0.037174  -0.024637 -0.030307 -0.024013  -0.029777  \nunemploye        -0.095539  -0.063317 -0.077889 -0.061715   0.982505  \ncreative_        -0.178863  -0.118538 -0.145820 -0.115540  -0.143269  \ndriver           -0.067379  -0.044654 -0.054932 -0.043525  -0.053971  \nexecutive        -0.075700  -0.050169 -0.061715 -0.048900  -0.060636  \nguard_etc        -0.102030  -0.067618 -0.083181 -0.065908  -0.081726  \nlabourer         -0.112774  -0.074739 -0.091941 -0.072849  -0.090332  \nmanager          -0.090458  -0.059950 -0.073747 -0.058433  -0.072457  \noffice_st        -0.122927  -0.081468 -0.100218 -0.079407  -0.098465  \nproductio         1.000000  -0.077664 -0.095539 -0.075700  -0.093867  \nprofessio        -0.077664   1.000000 -0.063317 -0.050169  -0.062209  \nsales            -0.095539  -0.063317  1.000000 -0.061715  -0.076527  \nsemi_pro         -0.075700  -0.050169 -0.061715  1.000000  -0.060636  \nunemploye        -0.093867  -0.062209 -0.076527 -0.060636   1.000000  \n\n[31 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Time_at_address</th>\n      <th>Res_status</th>\n      <th>Telephone</th>\n      <th>Time_employed</th>\n      <th>Time_bank</th>\n      <th>Liab_ref</th>\n      <th>Acc_ref</th>\n      <th>Home_Expn</th>\n      <th>...</th>\n      <th>executive</th>\n      <th>guard_etc</th>\n      <th>labourer</th>\n      <th>manager</th>\n      <th>office_st</th>\n      <th>productio</th>\n      <th>professio</th>\n      <th>sales</th>\n      <th>semi_pro</th>\n      <th>unemploye</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Sex</th>\n      <td>1.000000</td>\n      <td>0.025167</td>\n      <td>-0.031594</td>\n      <td>0.121713</td>\n      <td>0.121713</td>\n      <td>0.077239</td>\n      <td>-0.072303</td>\n      <td>0.010508</td>\n      <td>0.095826</td>\n      <td>0.115355</td>\n      <td>...</td>\n      <td>0.033932</td>\n      <td>0.022947</td>\n      <td>-0.008220</td>\n      <td>0.141564</td>\n      <td>-0.239058</td>\n      <td>0.089171</td>\n      <td>-0.028788</td>\n      <td>-0.116177</td>\n      <td>0.057602</td>\n      <td>-0.085110</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>0.025167</td>\n      <td>1.000000</td>\n      <td>0.217342</td>\n      <td>-0.080265</td>\n      <td>-0.080265</td>\n      <td>0.426890</td>\n      <td>0.208736</td>\n      <td>0.049109</td>\n      <td>-0.040445</td>\n      <td>-0.072254</td>\n      <td>...</td>\n      <td>0.195693</td>\n      <td>0.028675</td>\n      <td>-0.035318</td>\n      <td>0.056127</td>\n      <td>-0.085265</td>\n      <td>-0.025142</td>\n      <td>-0.008012</td>\n      <td>-0.061906</td>\n      <td>-0.002900</td>\n      <td>0.210038</td>\n    </tr>\n    <tr>\n      <th>Time_at_address</th>\n      <td>-0.031594</td>\n      <td>0.217342</td>\n      <td>1.000000</td>\n      <td>-0.100614</td>\n      <td>-0.100614</td>\n      <td>0.278849</td>\n      <td>0.202083</td>\n      <td>-0.049978</td>\n      <td>-0.144258</td>\n      <td>-0.267470</td>\n      <td>...</td>\n      <td>0.194672</td>\n      <td>-0.074592</td>\n      <td>-0.027105</td>\n      <td>-0.062565</td>\n      <td>0.060743</td>\n      <td>0.007001</td>\n      <td>-0.023361</td>\n      <td>0.018662</td>\n      <td>-0.069254</td>\n      <td>0.028853</td>\n    </tr>\n    <tr>\n      <th>Res_status</th>\n      <td>0.121713</td>\n      <td>-0.080265</td>\n      <td>-0.100614</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-0.074690</td>\n      <td>-0.132413</td>\n      <td>0.018827</td>\n      <td>-0.000201</td>\n      <td>-0.006477</td>\n      <td>...</td>\n      <td>-0.013801</td>\n      <td>-0.059316</td>\n      <td>0.103196</td>\n      <td>-0.007468</td>\n      <td>-0.141542</td>\n      <td>0.015006</td>\n      <td>0.058154</td>\n      <td>-0.043244</td>\n      <td>0.012631</td>\n      <td>0.048437</td>\n    </tr>\n    <tr>\n      <th>Telephone</th>\n      <td>0.121713</td>\n      <td>-0.080265</td>\n      <td>-0.100614</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>-0.074690</td>\n      <td>-0.132413</td>\n      <td>0.018827</td>\n      <td>-0.000201</td>\n      <td>-0.006477</td>\n      <td>...</td>\n      <td>-0.013801</td>\n      <td>-0.059316</td>\n      <td>0.103196</td>\n      <td>-0.007468</td>\n      <td>-0.141542</td>\n      <td>0.015006</td>\n      <td>0.058154</td>\n      <td>-0.043244</td>\n      <td>0.012631</td>\n      <td>0.048437</td>\n    </tr>\n    <tr>\n      <th>Time_employed</th>\n      <td>0.077239</td>\n      <td>0.426890</td>\n      <td>0.278849</td>\n      <td>-0.074690</td>\n      <td>-0.074690</td>\n      <td>1.000000</td>\n      <td>0.291542</td>\n      <td>0.122561</td>\n      <td>-0.025000</td>\n      <td>-0.110933</td>\n      <td>...</td>\n      <td>0.158402</td>\n      <td>-0.048504</td>\n      <td>-0.076296</td>\n      <td>0.085916</td>\n      <td>0.045731</td>\n      <td>-0.005221</td>\n      <td>0.065455</td>\n      <td>-0.080398</td>\n      <td>0.001919</td>\n      <td>-0.042615</td>\n    </tr>\n    <tr>\n      <th>Time_bank</th>\n      <td>-0.072303</td>\n      <td>0.208736</td>\n      <td>0.202083</td>\n      <td>-0.132413</td>\n      <td>-0.132413</td>\n      <td>0.291542</td>\n      <td>1.000000</td>\n      <td>0.051000</td>\n      <td>-0.158334</td>\n      <td>-0.111761</td>\n      <td>...</td>\n      <td>0.070908</td>\n      <td>-0.079085</td>\n      <td>-0.102461</td>\n      <td>-0.004365</td>\n      <td>0.115238</td>\n      <td>-0.035694</td>\n      <td>0.030341</td>\n      <td>-0.087884</td>\n      <td>0.042998</td>\n      <td>-0.026283</td>\n    </tr>\n    <tr>\n      <th>Liab_ref</th>\n      <td>0.010508</td>\n      <td>0.049109</td>\n      <td>-0.049978</td>\n      <td>0.018827</td>\n      <td>0.018827</td>\n      <td>0.122561</td>\n      <td>0.051000</td>\n      <td>1.000000</td>\n      <td>0.033197</td>\n      <td>0.127133</td>\n      <td>...</td>\n      <td>-0.047445</td>\n      <td>0.051444</td>\n      <td>0.044265</td>\n      <td>0.041821</td>\n      <td>-0.005693</td>\n      <td>0.037271</td>\n      <td>0.030484</td>\n      <td>-0.057168</td>\n      <td>-0.003053</td>\n      <td>-0.086354</td>\n    </tr>\n    <tr>\n      <th>Acc_ref</th>\n      <td>0.095826</td>\n      <td>-0.040445</td>\n      <td>-0.144258</td>\n      <td>-0.000201</td>\n      <td>-0.000201</td>\n      <td>-0.025000</td>\n      <td>-0.158334</td>\n      <td>0.033197</td>\n      <td>1.000000</td>\n      <td>0.096426</td>\n      <td>...</td>\n      <td>0.023691</td>\n      <td>-0.017403</td>\n      <td>0.029235</td>\n      <td>0.254292</td>\n      <td>-0.071914</td>\n      <td>-0.036777</td>\n      <td>-0.063317</td>\n      <td>-0.077889</td>\n      <td>-0.019012</td>\n      <td>-0.041226</td>\n    </tr>\n    <tr>\n      <th>Home_Expn</th>\n      <td>0.115355</td>\n      <td>-0.072254</td>\n      <td>-0.267470</td>\n      <td>-0.006477</td>\n      <td>-0.006477</td>\n      <td>-0.110933</td>\n      <td>-0.111761</td>\n      <td>0.127133</td>\n      <td>0.096426</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>-0.022788</td>\n      <td>0.070586</td>\n      <td>-0.024372</td>\n      <td>0.121765</td>\n      <td>-0.017424</td>\n      <td>0.048673</td>\n      <td>0.112318</td>\n      <td>-0.049655</td>\n      <td>0.094591</td>\n      <td>-0.139506</td>\n    </tr>\n    <tr>\n      <th>Balance</th>\n      <td>-0.045248</td>\n      <td>0.101819</td>\n      <td>0.072235</td>\n      <td>-0.068829</td>\n      <td>-0.068829</td>\n      <td>0.112719</td>\n      <td>0.153435</td>\n      <td>-0.013128</td>\n      <td>-0.065739</td>\n      <td>0.080366</td>\n      <td>...</td>\n      <td>0.153182</td>\n      <td>-0.025923</td>\n      <td>-0.053978</td>\n      <td>-0.023879</td>\n      <td>-0.008416</td>\n      <td>-0.028536</td>\n      <td>0.004505</td>\n      <td>-0.028959</td>\n      <td>0.138420</td>\n      <td>-0.020692</td>\n    </tr>\n    <tr>\n      <th>Decision</th>\n      <td>0.052564</td>\n      <td>-0.181241</td>\n      <td>-0.163298</td>\n      <td>0.139104</td>\n      <td>0.139104</td>\n      <td>-0.339833</td>\n      <td>-0.455942</td>\n      <td>-0.068508</td>\n      <td>0.106354</td>\n      <td>0.087311</td>\n      <td>...</td>\n      <td>-0.067796</td>\n      <td>0.131258</td>\n      <td>0.107222</td>\n      <td>0.029066</td>\n      <td>-0.133674</td>\n      <td>-0.028458</td>\n      <td>-0.165153</td>\n      <td>0.033932</td>\n      <td>-0.134504</td>\n      <td>0.173276</td>\n    </tr>\n    <tr>\n      <th>governmen</th>\n      <td>-0.071354</td>\n      <td>0.011700</td>\n      <td>0.032959</td>\n      <td>0.006508</td>\n      <td>0.006508</td>\n      <td>0.135908</td>\n      <td>0.097365</td>\n      <td>-0.041223</td>\n      <td>-0.066981</td>\n      <td>0.059496</td>\n      <td>...</td>\n      <td>-0.079377</td>\n      <td>-0.036600</td>\n      <td>0.019390</td>\n      <td>-0.080452</td>\n      <td>0.179558</td>\n      <td>-0.050329</td>\n      <td>0.191944</td>\n      <td>-0.089877</td>\n      <td>0.117460</td>\n      <td>-0.133296</td>\n    </tr>\n    <tr>\n      <th>military</th>\n      <td>0.033287</td>\n      <td>-0.054508</td>\n      <td>-0.022068</td>\n      <td>-0.026127</td>\n      <td>-0.026127</td>\n      <td>-0.027837</td>\n      <td>-0.003413</td>\n      <td>0.052702</td>\n      <td>-0.013490</td>\n      <td>-0.005677</td>\n      <td>...</td>\n      <td>-0.010689</td>\n      <td>-0.014407</td>\n      <td>-0.015924</td>\n      <td>-0.012773</td>\n      <td>-0.017357</td>\n      <td>-0.016547</td>\n      <td>-0.010966</td>\n      <td>-0.013490</td>\n      <td>-0.010689</td>\n      <td>-0.013254</td>\n    </tr>\n    <tr>\n      <th>private_s</th>\n      <td>0.043589</td>\n      <td>-0.247584</td>\n      <td>-0.083958</td>\n      <td>-0.021999</td>\n      <td>-0.021999</td>\n      <td>-0.172712</td>\n      <td>-0.115185</td>\n      <td>0.037822</td>\n      <td>0.089868</td>\n      <td>0.035104</td>\n      <td>...</td>\n      <td>-0.190084</td>\n      <td>-0.203628</td>\n      <td>0.081608</td>\n      <td>0.130195</td>\n      <td>-0.004043</td>\n      <td>0.175375</td>\n      <td>-0.066073</td>\n      <td>0.163973</td>\n      <td>-0.030814</td>\n      <td>-0.348558</td>\n    </tr>\n    <tr>\n      <th>retired</th>\n      <td>0.021153</td>\n      <td>0.309407</td>\n      <td>0.271421</td>\n      <td>-0.033319</td>\n      <td>-0.033319</td>\n      <td>0.265212</td>\n      <td>0.155554</td>\n      <td>-0.022658</td>\n      <td>-0.038472</td>\n      <td>-0.149999</td>\n      <td>...</td>\n      <td>0.623377</td>\n      <td>-0.041086</td>\n      <td>-0.045412</td>\n      <td>-0.036426</td>\n      <td>-0.049501</td>\n      <td>-0.047189</td>\n      <td>-0.031274</td>\n      <td>-0.038472</td>\n      <td>-0.030483</td>\n      <td>-0.037799</td>\n    </tr>\n    <tr>\n      <th>self_empl</th>\n      <td>0.087138</td>\n      <td>0.114273</td>\n      <td>-0.058537</td>\n      <td>-0.007264</td>\n      <td>-0.007264</td>\n      <td>0.045330</td>\n      <td>0.030708</td>\n      <td>0.084938</td>\n      <td>0.010466</td>\n      <td>0.076962</td>\n      <td>...</td>\n      <td>0.010833</td>\n      <td>0.515114</td>\n      <td>-0.073270</td>\n      <td>-0.013948</td>\n      <td>-0.110322</td>\n      <td>-0.105172</td>\n      <td>-0.069701</td>\n      <td>-0.053673</td>\n      <td>-0.028552</td>\n      <td>-0.084243</td>\n    </tr>\n    <tr>\n      <th>student</th>\n      <td>-0.018208</td>\n      <td>-0.076762</td>\n      <td>0.030354</td>\n      <td>0.045143</td>\n      <td>0.045143</td>\n      <td>-0.042492</td>\n      <td>-0.035080</td>\n      <td>-0.012399</td>\n      <td>-0.030307</td>\n      <td>-0.043405</td>\n      <td>...</td>\n      <td>0.491076</td>\n      <td>-0.032366</td>\n      <td>-0.035774</td>\n      <td>-0.028695</td>\n      <td>-0.038995</td>\n      <td>-0.037174</td>\n      <td>-0.024637</td>\n      <td>-0.030307</td>\n      <td>-0.024013</td>\n      <td>-0.029777</td>\n    </tr>\n    <tr>\n      <th>unemploye</th>\n      <td>-0.077631</td>\n      <td>0.203320</td>\n      <td>0.020707</td>\n      <td>0.042843</td>\n      <td>0.042843</td>\n      <td>-0.047159</td>\n      <td>-0.031069</td>\n      <td>-0.093314</td>\n      <td>-0.043119</td>\n      <td>-0.142259</td>\n      <td>...</td>\n      <td>-0.061715</td>\n      <td>-0.083181</td>\n      <td>-0.061647</td>\n      <td>-0.073747</td>\n      <td>-0.100218</td>\n      <td>-0.095539</td>\n      <td>-0.063317</td>\n      <td>-0.077889</td>\n      <td>-0.061715</td>\n      <td>0.982505</td>\n    </tr>\n    <tr>\n      <th>creative_</th>\n      <td>0.092333</td>\n      <td>-0.100224</td>\n      <td>-0.043791</td>\n      <td>0.029843</td>\n      <td>0.029843</td>\n      <td>-0.005600</td>\n      <td>0.103602</td>\n      <td>-0.034575</td>\n      <td>-0.036148</td>\n      <td>-0.088680</td>\n      <td>...</td>\n      <td>-0.115540</td>\n      <td>-0.155727</td>\n      <td>-0.172127</td>\n      <td>-0.138066</td>\n      <td>-0.187623</td>\n      <td>-0.178863</td>\n      <td>-0.118538</td>\n      <td>-0.145820</td>\n      <td>-0.115540</td>\n      <td>-0.143269</td>\n    </tr>\n    <tr>\n      <th>driver</th>\n      <td>0.056538</td>\n      <td>-0.061793</td>\n      <td>0.036117</td>\n      <td>0.011242</td>\n      <td>0.011242</td>\n      <td>-0.064149</td>\n      <td>-0.085321</td>\n      <td>0.041735</td>\n      <td>0.135115</td>\n      <td>-0.032013</td>\n      <td>...</td>\n      <td>-0.043525</td>\n      <td>-0.058664</td>\n      <td>-0.064842</td>\n      <td>-0.052011</td>\n      <td>-0.070679</td>\n      <td>-0.067379</td>\n      <td>-0.044654</td>\n      <td>-0.054932</td>\n      <td>-0.043525</td>\n      <td>-0.053971</td>\n    </tr>\n    <tr>\n      <th>executive</th>\n      <td>0.033932</td>\n      <td>0.195693</td>\n      <td>0.194672</td>\n      <td>-0.013801</td>\n      <td>-0.013801</td>\n      <td>0.158402</td>\n      <td>0.070908</td>\n      <td>-0.047445</td>\n      <td>0.023691</td>\n      <td>-0.022788</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>-0.065908</td>\n      <td>-0.072849</td>\n      <td>-0.058433</td>\n      <td>-0.079407</td>\n      <td>-0.075700</td>\n      <td>-0.050169</td>\n      <td>-0.061715</td>\n      <td>-0.048900</td>\n      <td>-0.060636</td>\n    </tr>\n    <tr>\n      <th>guard_etc</th>\n      <td>0.022947</td>\n      <td>0.028675</td>\n      <td>-0.074592</td>\n      <td>-0.059316</td>\n      <td>-0.059316</td>\n      <td>-0.048504</td>\n      <td>-0.079085</td>\n      <td>0.051444</td>\n      <td>-0.017403</td>\n      <td>0.070586</td>\n      <td>...</td>\n      <td>-0.065908</td>\n      <td>1.000000</td>\n      <td>-0.098187</td>\n      <td>-0.078758</td>\n      <td>-0.107027</td>\n      <td>-0.102030</td>\n      <td>-0.067618</td>\n      <td>-0.083181</td>\n      <td>-0.065908</td>\n      <td>-0.081726</td>\n    </tr>\n    <tr>\n      <th>labourer</th>\n      <td>-0.008220</td>\n      <td>-0.035318</td>\n      <td>-0.027105</td>\n      <td>0.103196</td>\n      <td>0.103196</td>\n      <td>-0.076296</td>\n      <td>-0.102461</td>\n      <td>0.044265</td>\n      <td>0.029235</td>\n      <td>-0.024372</td>\n      <td>...</td>\n      <td>-0.072849</td>\n      <td>-0.098187</td>\n      <td>1.000000</td>\n      <td>-0.087051</td>\n      <td>-0.118297</td>\n      <td>-0.112774</td>\n      <td>-0.074739</td>\n      <td>-0.091941</td>\n      <td>-0.072849</td>\n      <td>-0.090332</td>\n    </tr>\n    <tr>\n      <th>manager</th>\n      <td>0.141564</td>\n      <td>0.056127</td>\n      <td>-0.062565</td>\n      <td>-0.007468</td>\n      <td>-0.007468</td>\n      <td>0.085916</td>\n      <td>-0.004365</td>\n      <td>0.041821</td>\n      <td>0.254292</td>\n      <td>0.121765</td>\n      <td>...</td>\n      <td>-0.058433</td>\n      <td>-0.078758</td>\n      <td>-0.087051</td>\n      <td>1.000000</td>\n      <td>-0.094888</td>\n      <td>-0.090458</td>\n      <td>-0.059950</td>\n      <td>-0.073747</td>\n      <td>-0.058433</td>\n      <td>-0.072457</td>\n    </tr>\n    <tr>\n      <th>office_st</th>\n      <td>-0.239058</td>\n      <td>-0.085265</td>\n      <td>0.060743</td>\n      <td>-0.141542</td>\n      <td>-0.141542</td>\n      <td>0.045731</td>\n      <td>0.115238</td>\n      <td>-0.005693</td>\n      <td>-0.071914</td>\n      <td>-0.017424</td>\n      <td>...</td>\n      <td>-0.079407</td>\n      <td>-0.107027</td>\n      <td>-0.118297</td>\n      <td>-0.094888</td>\n      <td>1.000000</td>\n      <td>-0.122927</td>\n      <td>-0.081468</td>\n      <td>-0.100218</td>\n      <td>-0.079407</td>\n      <td>-0.098465</td>\n    </tr>\n    <tr>\n      <th>productio</th>\n      <td>0.089171</td>\n      <td>-0.025142</td>\n      <td>0.007001</td>\n      <td>0.015006</td>\n      <td>0.015006</td>\n      <td>-0.005221</td>\n      <td>-0.035694</td>\n      <td>0.037271</td>\n      <td>-0.036777</td>\n      <td>0.048673</td>\n      <td>...</td>\n      <td>-0.075700</td>\n      <td>-0.102030</td>\n      <td>-0.112774</td>\n      <td>-0.090458</td>\n      <td>-0.122927</td>\n      <td>1.000000</td>\n      <td>-0.077664</td>\n      <td>-0.095539</td>\n      <td>-0.075700</td>\n      <td>-0.093867</td>\n    </tr>\n    <tr>\n      <th>professio</th>\n      <td>-0.028788</td>\n      <td>-0.008012</td>\n      <td>-0.023361</td>\n      <td>0.058154</td>\n      <td>0.058154</td>\n      <td>0.065455</td>\n      <td>0.030341</td>\n      <td>0.030484</td>\n      <td>-0.063317</td>\n      <td>0.112318</td>\n      <td>...</td>\n      <td>-0.050169</td>\n      <td>-0.067618</td>\n      <td>-0.074739</td>\n      <td>-0.059950</td>\n      <td>-0.081468</td>\n      <td>-0.077664</td>\n      <td>1.000000</td>\n      <td>-0.063317</td>\n      <td>-0.050169</td>\n      <td>-0.062209</td>\n    </tr>\n    <tr>\n      <th>sales</th>\n      <td>-0.116177</td>\n      <td>-0.061906</td>\n      <td>0.018662</td>\n      <td>-0.043244</td>\n      <td>-0.043244</td>\n      <td>-0.080398</td>\n      <td>-0.087884</td>\n      <td>-0.057168</td>\n      <td>-0.077889</td>\n      <td>-0.049655</td>\n      <td>...</td>\n      <td>-0.061715</td>\n      <td>-0.083181</td>\n      <td>-0.091941</td>\n      <td>-0.073747</td>\n      <td>-0.100218</td>\n      <td>-0.095539</td>\n      <td>-0.063317</td>\n      <td>1.000000</td>\n      <td>-0.061715</td>\n      <td>-0.076527</td>\n    </tr>\n    <tr>\n      <th>semi_pro</th>\n      <td>0.057602</td>\n      <td>-0.002900</td>\n      <td>-0.069254</td>\n      <td>0.012631</td>\n      <td>0.012631</td>\n      <td>0.001919</td>\n      <td>0.042998</td>\n      <td>-0.003053</td>\n      <td>-0.019012</td>\n      <td>0.094591</td>\n      <td>...</td>\n      <td>-0.048900</td>\n      <td>-0.065908</td>\n      <td>-0.072849</td>\n      <td>-0.058433</td>\n      <td>-0.079407</td>\n      <td>-0.075700</td>\n      <td>-0.050169</td>\n      <td>-0.061715</td>\n      <td>1.000000</td>\n      <td>-0.060636</td>\n    </tr>\n    <tr>\n      <th>unemploye</th>\n      <td>-0.085110</td>\n      <td>0.210038</td>\n      <td>0.028853</td>\n      <td>0.048437</td>\n      <td>0.048437</td>\n      <td>-0.042615</td>\n      <td>-0.026283</td>\n      <td>-0.086354</td>\n      <td>-0.041226</td>\n      <td>-0.139506</td>\n      <td>...</td>\n      <td>-0.060636</td>\n      <td>-0.081726</td>\n      <td>-0.090332</td>\n      <td>-0.072457</td>\n      <td>-0.098465</td>\n      <td>-0.093867</td>\n      <td>-0.062209</td>\n      <td>-0.076527</td>\n      <td>-0.060636</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>31 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data prepared for correlation\n",
    "\n",
    "corr = dataset.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns based on correlations\n",
    "\n",
    "# also dropping Time_at_address as it plays trivial role in decision making\n",
    "\n",
    "dataset.drop(['Telephone', 'Time_at_address'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Sex', 'Age', 'Res_status', 'Time_employed', 'Time_bank', 'Liab_ref',\n       'Acc_ref', 'Home_Expn', 'Balance', 'Decision', 'governmen', 'military',\n       'private_s', 'retired', 'self_empl', 'student', 'unemploye',\n       'creative_', 'driver', 'executive', 'guard_etc', 'labourer', 'manager',\n       'office_st', 'productio', 'professio', 'sales', 'semi_pro',\n       'unemploye'],\n      dtype='object')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns\n",
    "\n",
    "# inference => we have 33 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   Sex        Age  Res_status  Time_employed  Time_bank  Liab_ref  Acc_ref  \\\n0    1  50.750000           0              0          0         0        0   \n1    1  19.670000           1              0          0         1        0   \n2    0  52.830002           0              5         14         0        0   \n3    1  22.670000           1              2          0         0        0   \n4    1  29.250000           0              0          0         0        0   \n\n   Home_Expn  Balance  Decision  ...  executive  guard_etc  labourer  manager  \\\n0        145        0         1  ...        0.0        0.0       0.0      0.0   \n1        140        0         1  ...        0.0        0.0       1.0      0.0   \n2          0     2200         0  ...        0.0        0.0       0.0      0.0   \n3          0        0         0  ...        0.0        0.0       0.0      0.0   \n4        228        0         1  ...        0.0        0.0       0.0      0.0   \n\n   office_st  productio  professio  sales  semi_pro  unemploye  \n0        0.0        0.0        0.0    0.0       0.0        1.0  \n1        0.0        0.0        0.0    0.0       0.0        0.0  \n2        0.0        0.0        0.0    0.0       0.0        0.0  \n3        0.0        0.0        0.0    0.0       0.0        0.0  \n4        0.0        0.0        0.0    0.0       0.0        0.0  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Res_status</th>\n      <th>Time_employed</th>\n      <th>Time_bank</th>\n      <th>Liab_ref</th>\n      <th>Acc_ref</th>\n      <th>Home_Expn</th>\n      <th>Balance</th>\n      <th>Decision</th>\n      <th>...</th>\n      <th>executive</th>\n      <th>guard_etc</th>\n      <th>labourer</th>\n      <th>manager</th>\n      <th>office_st</th>\n      <th>productio</th>\n      <th>professio</th>\n      <th>sales</th>\n      <th>semi_pro</th>\n      <th>unemploye</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>50.750000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>145</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>19.670000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>140</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>52.830002</td>\n      <td>0</td>\n      <td>5</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2200</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>22.670000</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>29.250000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>228</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['Sex', 'Age', 'Res_status', 'Time_employed', 'Time_bank', 'Liab_ref',\n",
    "       'Acc_ref', 'Home_Expn', 'Balance', 'governmen', 'military',\n",
    "       'private_s', 'retired', 'self_empl', 'student', 'unemploye',\n",
    "       'creative_', 'driver', 'executive', 'guard_etc', 'labourer', 'manager',\n",
    "       'office_st', 'productio', 'professio', 'sales', 'semi_pro',\n",
    "       'unemploye']]\n",
    "\n",
    "y = dataset[['Decision']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy:  0.9463869463869464\n",
      "gini:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# applying decision tree classifier\n",
    "decision_tree_classifier_entropy = DecisionTreeClassifier(criterion = 'entropy', random_state=0)\n",
    "decision_tree_classifier_entropy = decision_tree_classifier_entropy.fit(X_train,y_train)\n",
    "\n",
    "decision_tree_classifier_gini = DecisionTreeClassifier(criterion = 'gini', random_state=0)\n",
    "decision_tree_classifier_gini = decision_tree_classifier_gini.fit(X_train,y_train)\n",
    "\n",
    "print(\"entropy: \", decision_tree_classifier_entropy.score(X, y))\n",
    "print(\"gini: \", decision_tree_classifier_gini.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_entropy = decision_tree_classifier_entropy.predict(X_test)\n",
    "predictions_gini = decision_tree_classifier_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy:\n",
      "Mean Absolute Error: 0.26744186046511625\n",
      "Mean Squared Error: 0.26744186046511625\n",
      "Root Mean Squared Error: 0.517147812975281\n",
      "\n",
      "Gini:\n",
      "Mean Absolute Error: 0.20930232558139536\n",
      "Mean Squared Error: 0.20930232558139536\n",
      "Root Mean Squared Error: 0.457495710997814\n"
     ]
    }
   ],
   "source": [
    "# calculating the statistical metrics for entropy\n",
    "print(\"Entropy:\")\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions_entropy))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions_entropy))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions_entropy)))\n",
    "\n",
    "\n",
    "# calculating the statistical metrics for Gini\n",
    "print(\"\\nGini:\")\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions_gini))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions_gini))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions_gini)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entropy\n",
      " [Text(0.6654094827586207, 0.96875, 'X[4] <= 2.5\\nentropy = 0.994\\nsamples = 343\\nvalue = [156, 187]'), Text(0.42564655172413796, 0.90625, 'X[3] <= 0.5\\nentropy = 0.885\\nsamples = 254\\nvalue = [77, 177]'), Text(0.25862068965517243, 0.84375, 'X[8] <= 5676.0\\nentropy = 0.716\\nsamples = 147\\nvalue = [29, 118]'), Text(0.2413793103448276, 0.78125, 'X[1] <= 18.0\\nentropy = 0.681\\nsamples = 144\\nvalue = [26, 118]'), Text(0.22413793103448276, 0.71875, 'entropy = 0.0\\nsamples = 14\\nvalue = [0, 14]'), Text(0.25862068965517243, 0.71875, 'X[7] <= 224.5\\nentropy = 0.722\\nsamples = 130\\nvalue = [26, 104]'), Text(0.1724137931034483, 0.65625, 'X[7] <= 104.0\\nentropy = 0.604\\nsamples = 88\\nvalue = [13, 75]'), Text(0.13793103448275862, 0.59375, 'X[28] <= 0.5\\nentropy = 0.888\\nsamples = 36\\nvalue = [11, 25]'), Text(0.1206896551724138, 0.53125, 'X[8] <= 722.0\\nentropy = 0.958\\nsamples = 29\\nvalue = [11, 18]'), Text(0.08620689655172414, 0.46875, 'X[1] <= 26.21\\nentropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'), Text(0.06896551724137931, 0.40625, 'X[8] <= 0.5\\nentropy = 1.0\\nsamples = 16\\nvalue = [8, 8]'), Text(0.05172413793103448, 0.34375, 'X[7] <= 24.5\\nentropy = 0.845\\nsamples = 11\\nvalue = [8, 3]'), Text(0.034482758620689655, 0.28125, 'X[1] <= 21.5\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'), Text(0.017241379310344827, 0.21875, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.05172413793103448, 0.21875, 'X[26] <= 0.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'), Text(0.034482758620689655, 0.15625, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.06896551724137931, 0.15625, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.06896551724137931, 0.28125, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0]'), Text(0.08620689655172414, 0.34375, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'), Text(0.10344827586206896, 0.40625, 'entropy = 0.0\\nsamples = 9\\nvalue = [0, 9]'), Text(0.15517241379310345, 0.46875, 'X[17] <= 0.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'), Text(0.13793103448275862, 0.40625, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.1724137931034483, 0.40625, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.15517241379310345, 0.53125, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7]'), Text(0.20689655172413793, 0.59375, 'X[8] <= 242.0\\nentropy = 0.235\\nsamples = 52\\nvalue = [2, 50]'), Text(0.1896551724137931, 0.53125, 'entropy = 0.0\\nsamples = 44\\nvalue = [0, 44]'), Text(0.22413793103448276, 0.53125, 'X[8] <= 350.0\\nentropy = 0.811\\nsamples = 8\\nvalue = [2, 6]'), Text(0.20689655172413793, 0.46875, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.2413793103448276, 0.46875, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'), Text(0.3448275862068966, 0.65625, 'X[19] <= 0.5\\nentropy = 0.893\\nsamples = 42\\nvalue = [13, 29]'), Text(0.3275862068965517, 0.59375, 'X[7] <= 239.5\\nentropy = 0.849\\nsamples = 40\\nvalue = [11, 29]'), Text(0.29310344827586204, 0.53125, 'X[21] <= 0.5\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'), Text(0.27586206896551724, 0.46875, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.3103448275862069, 0.46875, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.3620689655172414, 0.53125, 'X[1] <= 34.295\\nentropy = 0.764\\nsamples = 36\\nvalue = [8, 28]'), Text(0.3448275862068966, 0.46875, 'X[13] <= 0.5\\nentropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'), Text(0.3275862068965517, 0.40625, 'X[1] <= 22.625\\nentropy = 0.828\\nsamples = 23\\nvalue = [6, 17]'), Text(0.3103448275862069, 0.34375, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6]'), Text(0.3448275862068966, 0.34375, 'X[21] <= 0.5\\nentropy = 0.937\\nsamples = 17\\nvalue = [6, 11]'), Text(0.3275862068965517, 0.28125, 'X[5] <= 0.5\\nentropy = 0.985\\nsamples = 14\\nvalue = [6, 8]'), Text(0.29310344827586204, 0.21875, 'X[8] <= 272.0\\nentropy = 0.918\\nsamples = 6\\nvalue = [4, 2]'), Text(0.27586206896551724, 0.15625, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'), Text(0.3103448275862069, 0.15625, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.3620689655172414, 0.21875, 'X[8] <= 5.0\\nentropy = 0.811\\nsamples = 8\\nvalue = [2, 6]'), Text(0.3448275862068966, 0.15625, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'), Text(0.3793103448275862, 0.15625, 'X[0] <= 0.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2]'), Text(0.3620689655172414, 0.09375, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.39655172413793105, 0.09375, 'X[7] <= 295.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'), Text(0.3793103448275862, 0.03125, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.41379310344827586, 0.03125, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.3620689655172414, 0.28125, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'), Text(0.3620689655172414, 0.40625, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.3793103448275862, 0.46875, 'entropy = 0.0\\nsamples = 11\\nvalue = [0, 11]'), Text(0.3620689655172414, 0.59375, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.27586206896551724, 0.78125, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.5926724137931034, 0.84375, 'X[7] <= 90.0\\nentropy = 0.992\\nsamples = 107\\nvalue = [48, 59]'), Text(0.46551724137931033, 0.78125, 'X[3] <= 6.0\\nentropy = 0.918\\nsamples = 27\\nvalue = [18, 9]'), Text(0.4482758620689655, 0.71875, 'X[1] <= 45.665\\nentropy = 0.985\\nsamples = 21\\nvalue = [12, 9]'), Text(0.43103448275862066, 0.65625, 'X[1] <= 21.915\\nentropy = 0.874\\nsamples = 17\\nvalue = [12, 5]'), Text(0.41379310344827586, 0.59375, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'), Text(0.4482758620689655, 0.59375, 'X[4] <= 1.5\\nentropy = 0.961\\nsamples = 13\\nvalue = [8, 5]'), Text(0.43103448275862066, 0.53125, 'X[22] <= 0.5\\nentropy = 1.0\\nsamples = 10\\nvalue = [5, 5]'), Text(0.41379310344827586, 0.46875, 'X[8] <= 8.0\\nentropy = 0.954\\nsamples = 8\\nvalue = [5, 3]'), Text(0.39655172413793105, 0.40625, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.43103448275862066, 0.40625, 'X[8] <= 439.0\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'), Text(0.41379310344827586, 0.34375, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'), Text(0.4482758620689655, 0.34375, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.4482758620689655, 0.46875, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.46551724137931033, 0.53125, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.46551724137931033, 0.65625, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'), Text(0.4827586206896552, 0.71875, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'), Text(0.7198275862068966, 0.78125, 'X[7] <= 499.5\\nentropy = 0.954\\nsamples = 80\\nvalue = [30, 50]'), Text(0.7025862068965517, 0.71875, 'X[8] <= 2201.5\\nentropy = 0.935\\nsamples = 77\\nvalue = [27, 50]'), Text(0.6853448275862069, 0.65625, 'X[3] <= 3.5\\nentropy = 0.918\\nsamples = 75\\nvalue = [25, 50]'), Text(0.5948275862068966, 0.59375, 'X[5] <= 0.5\\nentropy = 0.826\\nsamples = 54\\nvalue = [14, 40]'), Text(0.5517241379310345, 0.53125, 'X[8] <= 17.5\\nentropy = 0.976\\nsamples = 22\\nvalue = [9, 13]'), Text(0.5172413793103449, 0.46875, 'X[8] <= 0.5\\nentropy = 0.619\\nsamples = 13\\nvalue = [2, 11]'), Text(0.5, 0.40625, 'X[7] <= 212.0\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3]'), Text(0.4827586206896552, 0.34375, 'X[24] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'), Text(0.46551724137931033, 0.28125, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.5, 0.28125, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.5172413793103449, 0.34375, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.5344827586206896, 0.40625, 'entropy = 0.0\\nsamples = 8\\nvalue = [0, 8]'), Text(0.5862068965517241, 0.46875, 'X[2] <= 0.5\\nentropy = 0.764\\nsamples = 9\\nvalue = [7, 2]'), Text(0.5689655172413793, 0.40625, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0]'), Text(0.603448275862069, 0.40625, 'X[21] <= 0.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 2]'), Text(0.5862068965517241, 0.34375, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.6206896551724138, 0.34375, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.6379310344827587, 0.53125, 'X[7] <= 266.0\\nentropy = 0.625\\nsamples = 32\\nvalue = [5, 27]'), Text(0.6206896551724138, 0.46875, 'entropy = 0.0\\nsamples = 16\\nvalue = [0, 16]'), Text(0.6551724137931034, 0.46875, 'X[11] <= 0.5\\nentropy = 0.896\\nsamples = 16\\nvalue = [5, 11]'), Text(0.6379310344827587, 0.40625, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5]'), Text(0.6724137931034483, 0.40625, 'X[1] <= 24.955\\nentropy = 0.994\\nsamples = 11\\nvalue = [5, 6]'), Text(0.6551724137931034, 0.34375, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.6896551724137931, 0.34375, 'X[3] <= 1.5\\nentropy = 0.991\\nsamples = 9\\nvalue = [5, 4]'), Text(0.6724137931034483, 0.28125, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'), Text(0.7068965517241379, 0.28125, 'X[1] <= 31.83\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'), Text(0.6896551724137931, 0.21875, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'), Text(0.7241379310344828, 0.21875, 'X[6] <= 0.5\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1]'), Text(0.7068965517241379, 0.15625, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.7413793103448276, 0.15625, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.7758620689655172, 0.59375, 'X[0] <= 0.5\\nentropy = 0.998\\nsamples = 21\\nvalue = [11, 10]'), Text(0.7586206896551724, 0.53125, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.7931034482758621, 0.53125, 'X[1] <= 36.795\\nentropy = 0.982\\nsamples = 19\\nvalue = [11, 8]'), Text(0.7586206896551724, 0.46875, 'X[23] <= 0.5\\nentropy = 0.722\\nsamples = 10\\nvalue = [8, 2]'), Text(0.7413793103448276, 0.40625, 'X[26] <= 0.5\\nentropy = 0.503\\nsamples = 9\\nvalue = [8, 1]'), Text(0.7241379310344828, 0.34375, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0]'), Text(0.7586206896551724, 0.34375, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.7758620689655172, 0.40625, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.8275862068965517, 0.46875, 'X[8] <= 50.0\\nentropy = 0.918\\nsamples = 9\\nvalue = [3, 6]'), Text(0.8103448275862069, 0.40625, 'X[2] <= 0.5\\nentropy = 1.0\\nsamples = 6\\nvalue = [3, 3]'), Text(0.7931034482758621, 0.34375, 'X[1] <= 44.29\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1]'), Text(0.7758620689655172, 0.28125, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.8103448275862069, 0.28125, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.8275862068965517, 0.34375, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.8448275862068966, 0.40625, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3]'), Text(0.7198275862068966, 0.65625, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.7370689655172413, 0.71875, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.9051724137931034, 0.90625, 'X[8] <= 255.0\\nentropy = 0.507\\nsamples = 89\\nvalue = [79, 10]'), Text(0.8620689655172413, 0.84375, 'X[11] <= 0.5\\nentropy = 0.811\\nsamples = 36\\nvalue = [27, 9]'), Text(0.8275862068965517, 0.78125, 'X[4] <= 5.5\\nentropy = 0.997\\nsamples = 15\\nvalue = [7, 8]'), Text(0.8103448275862069, 0.71875, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'), Text(0.8448275862068966, 0.71875, 'X[8] <= 1.5\\nentropy = 0.946\\nsamples = 11\\nvalue = [7, 4]'), Text(0.8275862068965517, 0.65625, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'), Text(0.8620689655172413, 0.65625, 'X[7] <= 340.5\\nentropy = 0.985\\nsamples = 7\\nvalue = [3, 4]'), Text(0.8448275862068966, 0.59375, 'X[17] <= 0.5\\nentropy = 0.722\\nsamples = 5\\nvalue = [1, 4]'), Text(0.8275862068965517, 0.53125, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4]'), Text(0.8620689655172413, 0.53125, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.8793103448275862, 0.59375, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.896551724137931, 0.78125, 'X[1] <= 19.96\\nentropy = 0.276\\nsamples = 21\\nvalue = [20, 1]'), Text(0.8793103448275862, 0.71875, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.9137931034482759, 0.71875, 'entropy = 0.0\\nsamples = 20\\nvalue = [20, 0]'), Text(0.9482758620689655, 0.84375, 'X[22] <= 0.5\\nentropy = 0.135\\nsamples = 53\\nvalue = [52, 1]'), Text(0.9310344827586207, 0.78125, 'entropy = 0.0\\nsamples = 50\\nvalue = [50, 0]'), Text(0.9655172413793104, 0.78125, 'X[7] <= 307.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1]'), Text(0.9482758620689655, 0.71875, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.9827586206896551, 0.71875, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]')]\n",
      "|--- feature_4 <= 2.50\n",
      "|   |--- feature_3 <= 0.50\n",
      "|   |   |--- feature_8 <= 5676.00\n",
      "|   |   |   |--- feature_1 <= 18.00\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_1 >  18.00\n",
      "|   |   |   |   |--- feature_7 <= 224.50\n",
      "|   |   |   |   |   |--- feature_7 <= 104.00\n",
      "|   |   |   |   |   |   |--- feature_28 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 722.00\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 26.21\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 24.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  24.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  26.21\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  722.00\n",
      "|   |   |   |   |   |   |   |   |--- feature_17 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_17 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_28 >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  104.00\n",
      "|   |   |   |   |   |   |--- feature_8 <= 242.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_8 >  242.00\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 350.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  350.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_7 >  224.50\n",
      "|   |   |   |   |   |--- feature_19 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_7 <= 239.50\n",
      "|   |   |   |   |   |   |   |--- feature_21 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_21 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_7 >  239.50\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 34.29\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 22.62\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  22.62\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_21 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_21 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_13 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  34.29\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_19 >  0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_8 >  5676.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- feature_3 >  0.50\n",
      "|   |   |--- feature_7 <= 90.00\n",
      "|   |   |   |--- feature_3 <= 6.00\n",
      "|   |   |   |   |--- feature_1 <= 45.67\n",
      "|   |   |   |   |   |--- feature_1 <= 21.91\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_1 >  21.91\n",
      "|   |   |   |   |   |   |--- feature_4 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_22 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 8.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  8.00\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 439.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  439.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_22 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_4 >  1.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_1 >  45.67\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_3 >  6.00\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_7 >  90.00\n",
      "|   |   |   |--- feature_7 <= 499.50\n",
      "|   |   |   |   |--- feature_8 <= 2201.50\n",
      "|   |   |   |   |   |--- feature_3 <= 3.50\n",
      "|   |   |   |   |   |   |--- feature_5 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 17.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 212.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_24 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_24 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  212.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  17.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_2 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_21 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_21 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_5 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_7 <= 266.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_7 >  266.00\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_11 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 24.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  24.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_3 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_3 >  1.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |--- feature_3 >  3.50\n",
      "|   |   |   |   |   |   |--- feature_0 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_0 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 36.79\n",
      "|   |   |   |   |   |   |   |   |--- feature_23 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_26 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_26 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_23 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  36.79\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 50.00\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_2 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 <= 44.29\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_1 >  44.29\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_2 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  50.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_8 >  2201.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_7 >  499.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|--- feature_4 >  2.50\n",
      "|   |--- feature_8 <= 255.00\n",
      "|   |   |--- feature_11 <= 0.50\n",
      "|   |   |   |--- feature_4 <= 5.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_4 >  5.50\n",
      "|   |   |   |   |--- feature_8 <= 1.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_8 >  1.50\n",
      "|   |   |   |   |   |--- feature_7 <= 340.50\n",
      "|   |   |   |   |   |   |--- feature_17 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_17 >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_7 >  340.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_11 >  0.50\n",
      "|   |   |   |--- feature_1 <= 19.96\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_1 >  19.96\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- feature_8 >  255.00\n",
      "|   |   |--- feature_22 <= 0.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- feature_22 >  0.50\n",
      "|   |   |   |--- feature_7 <= 307.00\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_7 >  307.00\n",
      "|   |   |   |   |--- class: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#entropy graph\n",
    "tree_entropy =  tree.DecisionTreeClassifier(criterion = 'entropy', random_state=0)\n",
    "tree_entropy = tree_entropy.fit(X_train, y_train)\n",
    "\n",
    "print('\\nEntropy\\n', tree.plot_tree(tree_entropy))\n",
    "\n",
    "# word format representation\n",
    "text_representation_entropy = tree.export_text(decision_tree_classifier_entropy)\n",
    "print(text_representation_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gini\n",
      " [Text(0.6485445205479452, 0.9642857142857143, 'X[4] <= 2.5\\ngini = 0.496\\nsamples = 343\\nvalue = [156, 187]'), Text(0.3929794520547945, 0.8928571428571429, 'X[3] <= 0.5\\ngini = 0.422\\nsamples = 254\\nvalue = [77, 177]'), Text(0.2328767123287671, 0.8214285714285714, 'X[8] <= 5676.0\\ngini = 0.317\\nsamples = 147\\nvalue = [29, 118]'), Text(0.2191780821917808, 0.75, 'X[7] <= 224.5\\ngini = 0.296\\nsamples = 144\\nvalue = [26, 118]'), Text(0.1506849315068493, 0.6785714285714286, 'X[7] <= 104.0\\ngini = 0.224\\nsamples = 101\\nvalue = [13, 88]'), Text(0.1232876712328767, 0.6071428571428571, 'X[15] <= 0.5\\ngini = 0.405\\nsamples = 39\\nvalue = [11, 28]'), Text(0.1095890410958904, 0.5357142857142857, 'X[8] <= 722.0\\ngini = 0.458\\nsamples = 31\\nvalue = [11, 20]'), Text(0.0821917808219178, 0.4642857142857143, 'X[8] <= 0.5\\ngini = 0.417\\nsamples = 27\\nvalue = [8, 19]'), Text(0.0684931506849315, 0.39285714285714285, 'X[1] <= 26.21\\ngini = 0.5\\nsamples = 16\\nvalue = [8, 8]'), Text(0.0547945205479452, 0.32142857142857145, 'X[7] <= 24.5\\ngini = 0.397\\nsamples = 11\\nvalue = [8, 3]'), Text(0.0410958904109589, 0.25, 'X[17] <= 0.5\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'), Text(0.0273972602739726, 0.17857142857142858, 'X[26] <= 0.5\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'), Text(0.0136986301369863, 0.10714285714285714, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.0410958904109589, 0.10714285714285714, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.0547945205479452, 0.17857142857142858, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.0684931506849315, 0.25, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'), Text(0.0821917808219178, 0.32142857142857145, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'), Text(0.0958904109589041, 0.39285714285714285, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 11]'), Text(0.136986301369863, 0.4642857142857143, 'X[17] <= 0.5\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'), Text(0.1232876712328767, 0.39285714285714285, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.1506849315068493, 0.39285714285714285, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.136986301369863, 0.5357142857142857, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8]'), Text(0.1780821917808219, 0.6071428571428571, 'X[8] <= 242.0\\ngini = 0.062\\nsamples = 62\\nvalue = [2, 60]'), Text(0.1643835616438356, 0.5357142857142857, 'gini = 0.0\\nsamples = 53\\nvalue = [0, 53]'), Text(0.1917808219178082, 0.5357142857142857, 'X[8] <= 350.0\\ngini = 0.346\\nsamples = 9\\nvalue = [2, 7]'), Text(0.1780821917808219, 0.4642857142857143, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.2054794520547945, 0.4642857142857143, 'gini = 0.0\\nsamples = 7\\nvalue = [0, 7]'), Text(0.2876712328767123, 0.6785714285714286, 'X[19] <= 0.5\\ngini = 0.422\\nsamples = 43\\nvalue = [13, 30]'), Text(0.273972602739726, 0.6071428571428571, 'X[7] <= 239.5\\ngini = 0.393\\nsamples = 41\\nvalue = [11, 30]'), Text(0.2465753424657534, 0.5357142857142857, 'X[21] <= 0.5\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'), Text(0.2328767123287671, 0.4642857142857143, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.2602739726027397, 0.4642857142857143, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.3013698630136986, 0.5357142857142857, 'X[1] <= 34.295\\ngini = 0.339\\nsamples = 37\\nvalue = [8, 29]'), Text(0.2876712328767123, 0.4642857142857143, 'X[13] <= 0.5\\ngini = 0.426\\nsamples = 26\\nvalue = [8, 18]'), Text(0.273972602739726, 0.39285714285714285, 'X[1] <= 29.585\\ngini = 0.375\\nsamples = 24\\nvalue = [6, 18]'), Text(0.2465753424657534, 0.32142857142857145, 'X[25] <= 0.5\\ngini = 0.266\\nsamples = 19\\nvalue = [3, 16]'), Text(0.2328767123287671, 0.25, 'X[8] <= 907.5\\ngini = 0.198\\nsamples = 18\\nvalue = [2, 16]'), Text(0.2054794520547945, 0.17857142857142858, 'X[17] <= 0.5\\ngini = 0.117\\nsamples = 16\\nvalue = [1, 15]'), Text(0.1917808219178082, 0.10714285714285714, 'gini = 0.0\\nsamples = 13\\nvalue = [0, 13]'), Text(0.2191780821917808, 0.10714285714285714, 'X[1] <= 22.585\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'), Text(0.2054794520547945, 0.03571428571428571, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.2328767123287671, 0.03571428571428571, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.2602739726027397, 0.17857142857142858, 'X[4] <= 0.5\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'), Text(0.2465753424657534, 0.10714285714285714, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.273972602739726, 0.10714285714285714, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.2602739726027397, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.3013698630136986, 0.32142857142857145, 'X[8] <= 3.0\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 2]'), Text(0.2876712328767123, 0.25, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.3150684931506849, 0.25, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.3013698630136986, 0.39285714285714285, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.3150684931506849, 0.4642857142857143, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 11]'), Text(0.3013698630136986, 0.6071428571428571, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.2465753424657534, 0.75, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.553082191780822, 0.8214285714285714, 'X[7] <= 90.0\\ngini = 0.495\\nsamples = 107\\nvalue = [48, 59]'), Text(0.410958904109589, 0.75, 'X[20] <= 0.5\\ngini = 0.444\\nsamples = 27\\nvalue = [18, 9]'), Text(0.3972602739726027, 0.6785714285714286, 'X[3] <= 6.0\\ngini = 0.403\\nsamples = 25\\nvalue = [18, 7]'), Text(0.3835616438356164, 0.6071428571428571, 'X[1] <= 45.665\\ngini = 0.465\\nsamples = 19\\nvalue = [12, 7]'), Text(0.3698630136986301, 0.5357142857142857, 'X[22] <= 0.5\\ngini = 0.375\\nsamples = 16\\nvalue = [12, 4]'), Text(0.3424657534246575, 0.4642857142857143, 'X[8] <= 8.0\\ngini = 0.26\\nsamples = 13\\nvalue = [11, 2]'), Text(0.3287671232876712, 0.39285714285714285, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0]'), Text(0.3561643835616438, 0.39285714285714285, 'X[8] <= 211.0\\ngini = 0.444\\nsamples = 6\\nvalue = [4, 2]'), Text(0.3424657534246575, 0.32142857142857145, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.3698630136986301, 0.32142857142857145, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'), Text(0.3972602739726027, 0.4642857142857143, 'X[1] <= 39.335\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'), Text(0.3835616438356164, 0.39285714285714285, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.410958904109589, 0.39285714285714285, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.3972602739726027, 0.5357142857142857, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'), Text(0.410958904109589, 0.6071428571428571, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'), Text(0.4246575342465753, 0.6785714285714286, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.6952054794520548, 0.75, 'X[8] <= 1458.0\\ngini = 0.469\\nsamples = 80\\nvalue = [30, 50]'), Text(0.6232876712328768, 0.6785714285714286, 'X[3] <= 3.5\\ngini = 0.447\\nsamples = 74\\nvalue = [25, 49]'), Text(0.5205479452054794, 0.6071428571428571, 'X[5] <= 0.5\\ngini = 0.389\\nsamples = 53\\nvalue = [14, 39]'), Text(0.4794520547945205, 0.5357142857142857, 'X[8] <= 17.5\\ngini = 0.483\\nsamples = 22\\nvalue = [9, 13]'), Text(0.4520547945205479, 0.4642857142857143, 'X[8] <= 0.5\\ngini = 0.26\\nsamples = 13\\nvalue = [2, 11]'), Text(0.4383561643835616, 0.39285714285714285, 'X[7] <= 212.0\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'), Text(0.4246575342465753, 0.32142857142857145, 'X[1] <= 28.17\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'), Text(0.410958904109589, 0.25, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.4383561643835616, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.4520547945205479, 0.32142857142857145, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.4657534246575342, 0.39285714285714285, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8]'), Text(0.5068493150684932, 0.4642857142857143, 'X[2] <= 0.5\\ngini = 0.346\\nsamples = 9\\nvalue = [7, 2]'), Text(0.4931506849315068, 0.39285714285714285, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'), Text(0.5205479452054794, 0.39285714285714285, 'X[21] <= 0.5\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'), Text(0.5068493150684932, 0.32142857142857145, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.5342465753424658, 0.32142857142857145, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.5616438356164384, 0.5357142857142857, 'X[7] <= 260.0\\ngini = 0.271\\nsamples = 31\\nvalue = [5, 26]'), Text(0.547945205479452, 0.4642857142857143, 'gini = 0.0\\nsamples = 15\\nvalue = [0, 15]'), Text(0.5753424657534246, 0.4642857142857143, 'X[11] <= 0.5\\ngini = 0.43\\nsamples = 16\\nvalue = [5, 11]'), Text(0.5616438356164384, 0.39285714285714285, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'), Text(0.589041095890411, 0.39285714285714285, 'X[3] <= 1.5\\ngini = 0.496\\nsamples = 11\\nvalue = [5, 6]'), Text(0.5616438356164384, 0.32142857142857145, 'X[1] <= 24.955\\ngini = 0.444\\nsamples = 6\\nvalue = [4, 2]'), Text(0.547945205479452, 0.25, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.5753424657534246, 0.25, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'), Text(0.6164383561643836, 0.32142857142857145, 'X[1] <= 31.83\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4]'), Text(0.6027397260273972, 0.25, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'), Text(0.6301369863013698, 0.25, 'X[7] <= 380.0\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'), Text(0.6164383561643836, 0.17857142857142858, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.6438356164383562, 0.17857142857142858, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.726027397260274, 0.6071428571428571, 'X[8] <= 53.5\\ngini = 0.499\\nsamples = 21\\nvalue = [11, 10]'), Text(0.684931506849315, 0.5357142857142857, 'X[2] <= 0.5\\ngini = 0.469\\nsamples = 16\\nvalue = [10, 6]'), Text(0.6438356164383562, 0.4642857142857143, 'X[6] <= 0.5\\ngini = 0.346\\nsamples = 9\\nvalue = [7, 2]'), Text(0.6301369863013698, 0.39285714285714285, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'), Text(0.6575342465753424, 0.39285714285714285, 'X[3] <= 13.0\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'), Text(0.6438356164383562, 0.32142857142857145, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.6712328767123288, 0.32142857142857145, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.726027397260274, 0.4642857142857143, 'X[1] <= 36.795\\ngini = 0.49\\nsamples = 7\\nvalue = [3, 4]'), Text(0.7123287671232876, 0.39285714285714285, 'X[7] <= 171.0\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 2]'), Text(0.6986301369863014, 0.32142857142857145, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.726027397260274, 0.32142857142857145, 'X[27] <= 0.5\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'), Text(0.7123287671232876, 0.25, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.7397260273972602, 0.25, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.7397260273972602, 0.39285714285714285, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.7671232876712328, 0.5357142857142857, 'X[8] <= 175.0\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4]'), Text(0.7534246575342466, 0.4642857142857143, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'), Text(0.7808219178082192, 0.4642857142857143, 'X[1] <= 27.125\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'), Text(0.7671232876712328, 0.39285714285714285, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.7945205479452054, 0.39285714285714285, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.7671232876712328, 0.6785714285714286, 'X[20] <= 0.5\\ngini = 0.278\\nsamples = 6\\nvalue = [5, 1]'), Text(0.7534246575342466, 0.6071428571428571, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'), Text(0.7808219178082192, 0.6071428571428571, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.9041095890410958, 0.8928571428571429, 'X[3] <= 0.5\\ngini = 0.199\\nsamples = 89\\nvalue = [79, 10]'), Text(0.863013698630137, 0.8214285714285714, 'X[7] <= 277.0\\ngini = 0.444\\nsamples = 21\\nvalue = [14, 7]'), Text(0.8493150684931506, 0.75, 'X[1] <= 38.17\\ngini = 0.5\\nsamples = 14\\nvalue = [7, 7]'), Text(0.821917808219178, 0.6785714285714286, 'X[7] <= 114.5\\ngini = 0.444\\nsamples = 9\\nvalue = [3, 6]'), Text(0.8082191780821918, 0.6071428571428571, 'X[11] <= 0.5\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 2]'), Text(0.7945205479452054, 0.5357142857142857, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.821917808219178, 0.5357142857142857, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'), Text(0.8356164383561644, 0.6071428571428571, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'), Text(0.8767123287671232, 0.6785714285714286, 'X[4] <= 17.0\\ngini = 0.32\\nsamples = 5\\nvalue = [4, 1]'), Text(0.863013698630137, 0.6071428571428571, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'), Text(0.8904109589041096, 0.6071428571428571, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.8767123287671232, 0.75, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0]'), Text(0.9452054794520548, 0.8214285714285714, 'X[21] <= 0.5\\ngini = 0.084\\nsamples = 68\\nvalue = [65, 3]'), Text(0.9178082191780822, 0.75, 'X[9] <= 0.5\\ngini = 0.059\\nsamples = 66\\nvalue = [64, 2]'), Text(0.9041095890410958, 0.6785714285714286, 'gini = 0.0\\nsamples = 49\\nvalue = [49, 0]'), Text(0.9315068493150684, 0.6785714285714286, 'X[8] <= 255.0\\ngini = 0.208\\nsamples = 17\\nvalue = [15, 2]'), Text(0.9178082191780822, 0.6071428571428571, 'X[7] <= 116.5\\ngini = 0.48\\nsamples = 5\\nvalue = [3, 2]'), Text(0.9041095890410958, 0.5357142857142857, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'), Text(0.9315068493150684, 0.5357142857142857, 'X[7] <= 340.5\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'), Text(0.9178082191780822, 0.4642857142857143, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'), Text(0.9452054794520548, 0.4642857142857143, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'), Text(0.9452054794520548, 0.6071428571428571, 'gini = 0.0\\nsamples = 12\\nvalue = [12, 0]'), Text(0.9726027397260274, 0.75, 'X[3] <= 2.5\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'), Text(0.958904109589041, 0.6785714285714286, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'), Text(0.9863013698630136, 0.6785714285714286, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]')]\n",
      "|--- feature_4 <= 2.50\n",
      "|   |--- feature_3 <= 0.50\n",
      "|   |   |--- feature_8 <= 5676.00\n",
      "|   |   |   |--- feature_7 <= 224.50\n",
      "|   |   |   |   |--- feature_7 <= 104.00\n",
      "|   |   |   |   |   |--- feature_15 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_8 <= 722.00\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 26.21\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 <= 24.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_17 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_17 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_7 >  24.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  26.21\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_8 >  722.00\n",
      "|   |   |   |   |   |   |   |--- feature_17 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_17 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_15 >  0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_7 >  104.00\n",
      "|   |   |   |   |   |--- feature_8 <= 242.00\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_8 >  242.00\n",
      "|   |   |   |   |   |   |--- feature_8 <= 350.00\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_8 >  350.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_7 >  224.50\n",
      "|   |   |   |   |--- feature_19 <= 0.50\n",
      "|   |   |   |   |   |--- feature_7 <= 239.50\n",
      "|   |   |   |   |   |   |--- feature_21 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_21 >  0.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_7 >  239.50\n",
      "|   |   |   |   |   |   |--- feature_1 <= 34.29\n",
      "|   |   |   |   |   |   |   |--- feature_13 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 <= 29.59\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_25 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 <= 907.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_8 >  907.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_25 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_1 >  29.59\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 <= 3.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_8 >  3.00\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_13 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_1 >  34.29\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_19 >  0.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_8 >  5676.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- feature_3 >  0.50\n",
      "|   |   |--- feature_7 <= 90.00\n",
      "|   |   |   |--- feature_20 <= 0.50\n",
      "|   |   |   |   |--- feature_3 <= 6.00\n",
      "|   |   |   |   |   |--- feature_1 <= 45.67\n",
      "|   |   |   |   |   |   |--- feature_22 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 8.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  8.00\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 <= 211.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_8 >  211.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_22 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 39.33\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  39.33\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_1 >  45.67\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_3 >  6.00\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_20 >  0.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_7 >  90.00\n",
      "|   |   |   |--- feature_8 <= 1458.00\n",
      "|   |   |   |   |--- feature_3 <= 3.50\n",
      "|   |   |   |   |   |--- feature_5 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_8 <= 17.50\n",
      "|   |   |   |   |   |   |   |--- feature_8 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= 212.00\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 28.17\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  28.17\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  212.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_8 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_8 >  17.50\n",
      "|   |   |   |   |   |   |   |--- feature_2 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_2 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_21 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_21 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_5 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_7 <= 260.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_7 >  260.00\n",
      "|   |   |   |   |   |   |   |--- feature_11 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_11 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_3 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 24.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  24.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_3 >  1.50\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 <= 31.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_1 >  31.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 <= 380.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- feature_7 >  380.00\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_3 >  3.50\n",
      "|   |   |   |   |   |--- feature_8 <= 53.50\n",
      "|   |   |   |   |   |   |--- feature_2 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_6 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_6 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- feature_3 <= 13.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- feature_3 >  13.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_2 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 36.79\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 <= 171.00\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- feature_7 >  171.00\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_27 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- feature_27 >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  36.79\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_8 >  53.50\n",
      "|   |   |   |   |   |   |--- feature_8 <= 175.00\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_8 >  175.00\n",
      "|   |   |   |   |   |   |   |--- feature_1 <= 27.12\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_1 >  27.12\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_8 >  1458.00\n",
      "|   |   |   |   |--- feature_20 <= 0.50\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_20 >  0.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|--- feature_4 >  2.50\n",
      "|   |--- feature_3 <= 0.50\n",
      "|   |   |--- feature_7 <= 277.00\n",
      "|   |   |   |--- feature_1 <= 38.17\n",
      "|   |   |   |   |--- feature_7 <= 114.50\n",
      "|   |   |   |   |   |--- feature_11 <= 0.50\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_11 >  0.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_7 >  114.50\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_1 >  38.17\n",
      "|   |   |   |   |--- feature_4 <= 17.00\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_4 >  17.00\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_7 >  277.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- feature_3 >  0.50\n",
      "|   |   |--- feature_21 <= 0.50\n",
      "|   |   |   |--- feature_9 <= 0.50\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_9 >  0.50\n",
      "|   |   |   |   |--- feature_8 <= 255.00\n",
      "|   |   |   |   |   |--- feature_7 <= 116.50\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_7 >  116.50\n",
      "|   |   |   |   |   |   |--- feature_7 <= 340.50\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_7 >  340.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_8 >  255.00\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_21 >  0.50\n",
      "|   |   |   |--- feature_3 <= 2.50\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_3 >  2.50\n",
      "|   |   |   |   |--- class: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gini graph\n",
    "tree_gini =  tree.DecisionTreeClassifier(criterion = 'gini', random_state=0)\n",
    "tree_gini = tree_gini.fit(X_train, y_train)\n",
    "\n",
    "print('\\nGini\\n', tree.plot_tree(tree_gini))\n",
    "\n",
    "# word format representation\n",
    "text_representation_gini = tree.export_text(decision_tree_classifier_gini)\n",
    "print(text_representation_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Entropy: \n",
      " [[27  9]\n",
      " [14 36]]\n",
      "\n",
      "Confusion Matrix Gini: \n",
      " [[29  7]\n",
      " [11 39]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix:\n",
    "print(\"Confusion Matrix Entropy: \\n\", confusion_matrix(y_test, predictions_entropy))\n",
    "print(\"\\nConfusion Matrix Gini: \\n\", confusion_matrix(y_test, predictions_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: LinregressResult(slope=0.47000000000000025, intercept=0.2499999999999999, rvalue=0.46423291042530734, pvalue=6.7236546929196195e-06, stderr=0.09783976209915399, intercept_stderr=0.0746021192090157)\n",
      "\n",
      "Gini: LinregressResult(slope=0.5855555555555555, intercept=0.19444444444444442, rvalue=0.5791558491326325, pvalue=5.166052736765785e-09, stderr=0.08993032445681332, intercept_stderr=0.0685712295460565)\n"
     ]
    }
   ],
   "source": [
    "print('Entropy:', linregress(y_test.to_numpy().ravel(), np.array(predictions_entropy)))\n",
    "print('\\nGini:', linregress(y_test.to_numpy().ravel(), np.array(predictions_gini)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the decision path in a tree\n",
      "Entropy:\n",
      "  (0, 0)\t1\n",
      "  (0, 118)\t1\n",
      "  (0, 132)\t1\n",
      "  (0, 133)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 55)\t1\n",
      "  (1, 56)\t1\n",
      "  (1, 57)\t1\n",
      "  (1, 58)\t1\n",
      "  (1, 60)\t1\n",
      "  (1, 68)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 118)\t1\n",
      "  (2, 119)\t1\n",
      "  (2, 129)\t1\n",
      "  (2, 131)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 24)\t1\n",
      "  (3, 25)\t1\n",
      "  :\t:\n",
      "  (83, 118)\t1\n",
      "  (83, 132)\t1\n",
      "  (83, 133)\t1\n",
      "  (84, 0)\t1\n",
      "  (84, 1)\t1\n",
      "  (84, 2)\t1\n",
      "  (84, 3)\t1\n",
      "  (84, 5)\t1\n",
      "  (84, 29)\t1\n",
      "  (84, 30)\t1\n",
      "  (84, 34)\t1\n",
      "  (84, 35)\t1\n",
      "  (84, 36)\t1\n",
      "  (84, 38)\t1\n",
      "  (84, 39)\t1\n",
      "  (84, 43)\t1\n",
      "  (84, 44)\t1\n",
      "  (85, 0)\t1\n",
      "  (85, 1)\t1\n",
      "  (85, 2)\t1\n",
      "  (85, 3)\t1\n",
      "  (85, 5)\t1\n",
      "  (85, 6)\t1\n",
      "  (85, 24)\t1\n",
      "  (85, 25)\t1\n",
      "\n",
      "Gini:\n",
      "  (0, 0)\t1\n",
      "  (0, 120)\t1\n",
      "  (0, 132)\t1\n",
      "  (0, 133)\t1\n",
      "  (0, 135)\t1\n",
      "  (0, 141)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 53)\t1\n",
      "  (1, 54)\t1\n",
      "  (1, 55)\t1\n",
      "  (1, 56)\t1\n",
      "  (1, 57)\t1\n",
      "  (1, 58)\t1\n",
      "  (1, 60)\t1\n",
      "  (1, 62)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 120)\t1\n",
      "  (2, 132)\t1\n",
      "  (2, 133)\t1\n",
      "  (2, 134)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 3)\t1\n",
      "  :\t:\n",
      "  (82, 26)\t1\n",
      "  (83, 0)\t1\n",
      "  (83, 120)\t1\n",
      "  (83, 121)\t1\n",
      "  (83, 131)\t1\n",
      "  (84, 0)\t1\n",
      "  (84, 1)\t1\n",
      "  (84, 2)\t1\n",
      "  (84, 3)\t1\n",
      "  (84, 27)\t1\n",
      "  (84, 28)\t1\n",
      "  (84, 32)\t1\n",
      "  (84, 33)\t1\n",
      "  (84, 34)\t1\n",
      "  (84, 35)\t1\n",
      "  (84, 36)\t1\n",
      "  (84, 37)\t1\n",
      "  (84, 38)\t1\n",
      "  (85, 0)\t1\n",
      "  (85, 1)\t1\n",
      "  (85, 2)\t1\n",
      "  (85, 3)\t1\n",
      "  (85, 4)\t1\n",
      "  (85, 22)\t1\n",
      "  (85, 23)\t1\n"
     ]
    }
   ],
   "source": [
    "# returning the decision path in a tree\n",
    "print('the decision path in a tree')\n",
    "\n",
    "print('Entropy:')\n",
    "print(decision_tree_classifier_entropy.decision_path(X_test))\n",
    "\n",
    "print('\\nGini:')\n",
    "print(decision_tree_classifier_gini.decision_path(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy:\n",
      "Depth of the tree:  15\n",
      "\n",
      "Gini:\n",
      "Depth of the tree:  13\n"
     ]
    }
   ],
   "source": [
    "# returning the depth of the tree\n",
    "\n",
    "print('Entropy:')\n",
    "print('Depth of the tree: ',decision_tree_classifier_entropy.get_depth())\n",
    "\n",
    "print('\\nGini:')\n",
    "print('Depth of the tree: ',decision_tree_classifier_gini.get_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy:\n",
      "number of leaves of the tree:  69\n",
      "\n",
      "Gini:\n",
      "number of leaves of the tree:  73\n"
     ]
    }
   ],
   "source": [
    "# returning the number of leaves of the tree\n",
    "print('Entropy:')\n",
    "print('number of leaves of the tree: ',decision_tree_classifier_entropy.get_n_leaves())\n",
    "\n",
    "print('\\nGini:')\n",
    "print('number of leaves of the tree: ',decision_tree_classifier_gini.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy:\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 0, 'splitter': 'best'}\n",
      "\n",
      "Gini:\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 0, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# returning the parameters for our case\n",
    "print(\"Entropy:\")\n",
    "print(decision_tree_classifier_entropy.get_params())\n",
    "\n",
    "print(\"\\nGini:\")\n",
    "print(decision_tree_classifier_gini.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class log-probabilities: \n",
      "Entropy:\n",
      "[[  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]]\n",
      "\n",
      "Gini:\n",
      "[[  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [  0. -inf]\n",
      " [-inf   0.]\n",
      " [-inf   0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devsh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\tree\\_classes.py:1014: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n",
      "C:\\Users\\devsh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\tree\\_classes.py:1014: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    }
   ],
   "source": [
    "# Predicting class log-probabilities\n",
    "print('class log-probabilities: ')\n",
    "\n",
    "print('Entropy:')\n",
    "print(decision_tree_classifier_entropy.predict_log_proba(X_test))\n",
    "\n",
    "print('\\nGini:')\n",
    "print(decision_tree_classifier_gini.predict_log_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class probabilities: \n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [1., 0.],\n       [1., 0.],\n       [0., 1.],\n       [1., 0.],\n       [0., 1.],\n       [0., 1.]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting class probabilities\n",
    "print('class probabilities: ')\n",
    "decision_tree_classifier_entropy.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: Computing the pruning path during Minimal Cost-Complexity Pruning:\n",
      "{'ccp_alphas': array([0.        , 0.02325581, 0.03203358, 0.03584184, 0.03765053,\n",
      "       0.03773387, 0.06474182, 0.10551238, 0.11247915, 0.1795256 ,\n",
      "       0.24088088]), 'impurities': array([0.        , 0.02325581, 0.05528939, 0.12697308, 0.23992467,\n",
      "       0.27765854, 0.34240036, 0.44791274, 0.56039188, 0.73991748,\n",
      "       0.98079836])}\n",
      "\n",
      "Gini: Computing the pruning path during Minimal Cost-Complexity Pruning:\n",
      "{'ccp_alphas': array([0.        , 0.01094391, 0.0166113 , 0.01665288, 0.01744186,\n",
      "       0.03139535, 0.03322259, 0.04875919, 0.07834302, 0.15586566]), 'impurities': array([0.        , 0.02188782, 0.05511042, 0.12172192, 0.13916378,\n",
      "       0.17055913, 0.20378172, 0.25254091, 0.33088394, 0.48674959])}\n"
     ]
    }
   ],
   "source": [
    "# Computing the pruning path during Minimal Cost-Complexity Pruning\n",
    "print('Entropy: Computing the pruning path during Minimal Cost-Complexity Pruning:')\n",
    "print(decision_tree_classifier_entropy.cost_complexity_pruning_path(X_test,y_test))\n",
    "\n",
    "# Computing the pruning path during Minimal Cost-Complexity Pruning\n",
    "print('\\nGini: Computing the pruning path during Minimal Cost-Complexity Pruning:')\n",
    "print(decision_tree_classifier_gini.cost_complexity_pruning_path(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devsh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:  0.7925407925407926\n"
     ]
    }
   ],
   "source": [
    "# applying Random Forest Classifier\n",
    "random_forest_classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "random_forest_classifier = random_forest_classifier.fit(X_train,y_train)\n",
    "\n",
    "print(\"Random Forest Classifier: \", random_forest_classifier.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions_random_forest = random_forest_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Mean Absolute Error: 0.16279069767441862\n",
      "Mean Squared Error: 0.16279069767441862\n",
      "Root Mean Squared Error: 0.4034732923929645\n"
     ]
    }
   ],
   "source": [
    "# calculating the statistical metrics for random forest classifier\n",
    "print(\"Random Forest:\")\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions_random_forest))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, predictions_random_forest))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, predictions_random_forest)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest: \n",
      " [[24 12]\n",
      " [ 2 48]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix:\n",
    "print(\"Confusion Matrix Random Forest: \\n\", confusion_matrix(y_test, predictions_random_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: LinregressResult(slope=0.6266666666666667, intercept=0.3333333333333333, rvalue=0.6731479815970672, pvalue=1.2464939766709512e-12, stderr=0.07511543145271837, intercept_stderr=0.057274979532281584)\n"
     ]
    }
   ],
   "source": [
    "print('Entropy:', linregress(y_test.to_numpy().ravel(), np.array(predictions_random_forest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the decision path in a tree\n",
      "Random Forest Classifier:\n",
      "(<86x694 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 25777 stored elements in Compressed Sparse Row format>, array([  0,   7,  14,  21,  28,  35,  42,  49,  56,  63,  70,  77,  84,\n",
      "        89,  96, 103, 110, 117, 124, 131, 136, 143, 150, 157, 164, 171,\n",
      "       178, 185, 192, 199, 206, 213, 220, 227, 234, 241, 248, 255, 262,\n",
      "       269, 276, 283, 290, 297, 304, 311, 318, 325, 332, 339, 346, 353,\n",
      "       360, 367, 374, 381, 388, 395, 402, 407, 414, 421, 428, 435, 442,\n",
      "       449, 456, 463, 470, 477, 484, 491, 498, 505, 512, 519, 526, 533,\n",
      "       540, 547, 554, 561, 568, 575, 582, 589, 596, 603, 610, 617, 624,\n",
      "       631, 638, 645, 652, 659, 666, 673, 680, 687, 694], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "# returning the decision path in a forest\n",
    "print('the decision path in a tree')\n",
    "\n",
    "print('Random Forest Classifier:')\n",
    "print(random_forest_classifier.decision_path(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_forest_classifier:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# returning the parameters for our case\n",
    "print(\"Random_forest_classifier:\")\n",
    "print(random_forest_classifier.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Log Prob:\n",
      "[[-0.29742015 -1.35763649]\n",
      " [-0.48562725 -0.95532038]\n",
      " [-0.50057795 -0.93186188]\n",
      " [-1.05072386 -0.4302977 ]\n",
      " [-0.83054928 -0.57236392]\n",
      " [-0.97174893 -0.47549167]\n",
      " [-0.99081433 -0.46406009]\n",
      " [-1.56173388 -0.23543381]\n",
      " [-1.03639408 -0.43808879]\n",
      " [-0.53183975 -0.88557503]\n",
      " [-0.27408022 -1.4282465 ]\n",
      " [-1.09407891 -0.40773953]\n",
      " [-1.09629933 -0.4066236 ]\n",
      " [-0.50198122 -0.92970575]\n",
      " [-0.92611306 -0.5043306 ]\n",
      " [-0.42313585 -1.06418086]\n",
      " [-0.48400474 -0.95792107]\n",
      " [-0.59874466 -0.79739946]\n",
      " [-0.77723248 -0.61558709]\n",
      " [-1.10316178 -0.4031981 ]\n",
      " [-1.01195928 -0.4517804 ]\n",
      " [-0.50224637 -0.92929922]\n",
      " [-0.63218562 -0.7580677 ]\n",
      " [-0.88981026 -0.52887704]\n",
      " [-0.3279789  -1.27431736]\n",
      " [-0.43786211 -1.03680655]\n",
      " [-1.04941017 -0.43100481]\n",
      " [-0.69512064 -0.6911776 ]\n",
      " [-0.56336268 -0.84232375]\n",
      " [-0.93816953 -0.49650125]\n",
      " [-0.77847062 -0.61453496]\n",
      " [-0.86036434 -0.54992677]\n",
      " [-0.96883465 -0.47727006]\n",
      " [-0.87885765 -0.53658286]\n",
      " [-1.09238893 -0.40859137]\n",
      " [-1.11528967 -0.39722957]\n",
      " [-1.30196268 -0.3174507 ]\n",
      " [-0.8488203  -0.55847547]\n",
      " [-1.55950153 -0.23602725]\n",
      " [-1.16443837 -0.37410874]\n",
      " [-0.91220063 -0.51356168]\n",
      " [-0.84734079 -0.55958359]\n",
      " [-0.87785774 -0.53729356]\n",
      " [-1.35266365 -0.29914843]\n",
      " [-0.65267915 -0.7353222 ]\n",
      " [-1.12843929 -0.39087873]\n",
      " [-0.87665562 -0.53814959]\n",
      " [-0.99675769 -0.46056694]\n",
      " [-0.73981899 -0.64855685]\n",
      " [-1.04095154 -0.43559218]\n",
      " [-0.95614905 -0.48510952]\n",
      " [-0.73364805 -0.65422298]\n",
      " [-0.77512019 -0.61738762]\n",
      " [-1.11540178 -0.3971749 ]\n",
      " [-0.8118189  -0.58707629]\n",
      " [-1.10991567 -0.39986097]\n",
      " [-0.970779   -0.47608263]\n",
      " [-1.16774003 -0.37261438]\n",
      " [-0.63210138 -0.75816325]\n",
      " [-0.73699433 -0.65114212]\n",
      " [-0.68326218 -0.70313087]\n",
      " [-1.04084041 -0.43565285]\n",
      " [-0.78493444 -0.60908108]\n",
      " [-0.79425845 -0.60132714]\n",
      " [-0.38300925 -1.14509588]\n",
      " [-0.94444999 -0.49248388]\n",
      " [-0.39737866 -1.11498403]\n",
      " [-0.93617357 -0.49778668]\n",
      " [-0.98890825 -0.46518738]\n",
      " [-1.01760877 -0.4485682 ]\n",
      " [-0.96884597 -0.47726314]\n",
      " [-0.76224316 -0.62851845]\n",
      " [-0.57213283 -0.83084852]\n",
      " [-0.38259792 -1.14597783]\n",
      " [-0.67973852 -0.70673808]\n",
      " [-1.03832677 -0.4370279 ]\n",
      " [-0.85969815 -0.55041545]\n",
      " [-0.65747416 -0.73013999]\n",
      " [-1.02135832 -0.44645191]\n",
      " [-0.4165086  -1.07688458]\n",
      " [-0.44572032 -1.02265965]\n",
      " [-0.3073237  -1.32958332]\n",
      " [-0.93183134 -0.50059779]\n",
      " [-0.93537412 -0.49830273]\n",
      " [-1.10043459 -0.4045552 ]\n",
      " [-1.06862752 -0.42080153]]\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Log Prob:')\n",
    "print(random_forest_classifier.predict_log_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class probabilities RFC: \n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.74273189, 0.25726811],\n       [0.61531112, 0.38468888],\n       [0.60618022, 0.39381978],\n       [0.34968453, 0.65031547],\n       [0.43580984, 0.56419016],\n       [0.37842063, 0.62157937],\n       [0.37127423, 0.62872577],\n       [0.20977204, 0.79022796],\n       [0.35473151, 0.64526849],\n       [0.58752308, 0.41247692],\n       [0.76027108, 0.23972892],\n       [0.33484789, 0.66515211],\n       [0.33410521, 0.66589479],\n       [0.60533018, 0.39466982],\n       [0.3960903 , 0.6039097 ],\n       [0.65498965, 0.34501035],\n       [0.61631028, 0.38368972],\n       [0.54950102, 0.45049898],\n       [0.45967642, 0.54032358],\n       [0.33182028, 0.66817972],\n       [0.36350607, 0.63649393],\n       [0.6051697 , 0.3948303 ],\n       [0.53142903, 0.46857097],\n       [0.41073368, 0.58926632],\n       [0.72037822, 0.27962178],\n       [0.64541477, 0.35458523],\n       [0.35014422, 0.64985578],\n       [0.49901424, 0.50098576],\n       [0.5692915 , 0.4307085 ],\n       [0.39134352, 0.60865648],\n       [0.45910762, 0.54089238],\n       [0.42300794, 0.57699206],\n       [0.37952506, 0.62047494],\n       [0.41525701, 0.58474299],\n       [0.33541425, 0.66458575],\n       [0.32782031, 0.67217969],\n       [0.27199743, 0.72800257],\n       [0.42791945, 0.57208055],\n       [0.21024084, 0.78975916],\n       [0.3120979 , 0.6879021 ],\n       [0.40163939, 0.59836061],\n       [0.42855303, 0.57144697],\n       [0.41567244, 0.58432756],\n       [0.25855065, 0.74144935],\n       [0.52064901, 0.47935099],\n       [0.32353781, 0.67646219],\n       [0.41617243, 0.58382757],\n       [0.36907416, 0.63092584],\n       [0.47720029, 0.52279971],\n       [0.35311852, 0.64688148],\n       [0.38437023, 0.61562977],\n       [0.48015417, 0.51984583],\n       [0.46064841, 0.53935159],\n       [0.32778356, 0.67221644],\n       [0.44404965, 0.55595035],\n       [0.32958676, 0.67041324],\n       [0.37878785, 0.62121215],\n       [0.31106916, 0.68893084],\n       [0.5314738 , 0.4685262 ],\n       [0.47855012, 0.52144988],\n       [0.50496701, 0.49503299],\n       [0.35315776, 0.64684224],\n       [0.45614961, 0.54385039],\n       [0.45191623, 0.54808377],\n       [0.68180659, 0.31819341],\n       [0.38889341, 0.61110659],\n       [0.67207949, 0.32792051],\n       [0.39212541, 0.60787459],\n       [0.37198258, 0.62801742],\n       [0.36145824, 0.63854176],\n       [0.37952076, 0.62047924],\n       [0.46661855, 0.53338145],\n       [0.56432055, 0.43567945],\n       [0.6820871 , 0.3179129 ],\n       [0.50674948, 0.49325052],\n       [0.35404659, 0.64595341],\n       [0.42328983, 0.57671017],\n       [0.51815847, 0.48184153],\n       [0.36010547, 0.63989453],\n       [0.65934484, 0.34065516],\n       [0.64036284, 0.35963716],\n       [0.73541251, 0.26458749],\n       [0.39383181, 0.60616819],\n       [0.39243902, 0.60756098],\n       [0.33272645, 0.66727355],\n       [0.34347961, 0.65652039]])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting class probabilities\n",
    "print('class probabilities RFC: ')\n",
    "random_forest_classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}